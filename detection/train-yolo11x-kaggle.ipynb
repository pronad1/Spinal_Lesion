{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14585996,"sourceType":"datasetVersion","datasetId":9220832}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ad4e317d","cell_type":"markdown","source":"# YOLO11-x Training on VinDr-SpineXR Dataset\n## Kaggle GPU Optimized (Tesla P100/T4 16GB)\n\n**Model**: YOLO11-x (65M parameters)\n\n**Expected Performance**: 35-39% mAP@0.5 (vs 32-36% with YOLO11-l)\n\n**Training Time**: ~10-12 hours on Kaggle GPU\n---","metadata":{}},{"id":"e2ecb2cc","cell_type":"markdown","source":"## Step 1: Setup Environment","metadata":{}},{"id":"0e670d5a","cell_type":"code","source":"# Check GPU availability\nimport torch\nprint(f\"PyTorch version: {torch.__version__}\")\nprint(f\"CUDA available: {torch.cuda.is_available()}\")\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\nelse:\n    print(\"WARNING: No GPU detected! Training will be extremely slow.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:05:50.309166Z","iopub.execute_input":"2026-01-23T12:05:50.309895Z","iopub.status.idle":"2026-01-23T12:05:56.870540Z","shell.execute_reply.started":"2026-01-23T12:05:50.309867Z","shell.execute_reply":"2026-01-23T12:05:56.869868Z"}},"outputs":[{"name":"stdout","text":"PyTorch version: 2.8.0+cu126\nCUDA available: True\nGPU: Tesla T4\nGPU Memory: 14.7 GB\n","output_type":"stream"}],"execution_count":1},{"id":"1ef45f66","cell_type":"code","source":"# Install/Upgrade Ultralytics (YOLO11)\n!pip install -U ultralytics\n!pip install -U opencv-python-headless\n\n# Verify installation\nfrom ultralytics import YOLO\nprint(\"‚úì Ultralytics installed successfully!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:05:56.871982Z","iopub.execute_input":"2026-01-23T12:05:56.872308Z","iopub.status.idle":"2026-01-23T12:06:16.631419Z","shell.execute_reply.started":"2026-01-23T12:05:56.872285Z","shell.execute_reply":"2026-01-23T12:06:16.630626Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting ultralytics\n  Downloading ultralytics-8.4.7-py3-none-any.whl.metadata (38 kB)\nRequirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\nRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\nRequirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\nRequirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\nRequirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\nRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.5)\nRequirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.15.3)\nRequirement already satisfied: torch<2.10,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\nRequirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\nRequirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\nCollecting ultralytics-thop>=2.0.18 (from ultralytics)\n  Downloading ultralytics_thop-2.0.18-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2026.1.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<2.10,>=1.8.0->ultralytics) (3.4.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<2.10,>=1.8.0->ultralytics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<2.10,>=1.8.0->ultralytics) (3.0.3)\nDownloading ultralytics-8.4.7-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading ultralytics_thop-2.0.18-py3-none-any.whl (28 kB)\nInstalling collected packages: ultralytics-thop, ultralytics\nSuccessfully installed ultralytics-8.4.7 ultralytics-thop-2.0.18\nRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\nCollecting opencv-python-headless\n  Downloading opencv_python_headless-4.13.0.90-cp37-abi3-manylinux_2_28_x86_64.whl.metadata (19 kB)\nRequirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from opencv-python-headless) (2.0.2)\nDownloading opencv_python_headless-4.13.0.90-cp37-abi3-manylinux_2_28_x86_64.whl (62.5 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.5/62.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: opencv-python-headless\n  Attempting uninstall: opencv-python-headless\n    Found existing installation: opencv-python-headless 4.12.0.88\n    Uninstalling opencv-python-headless-4.12.0.88:\n      Successfully uninstalled opencv-python-headless-4.12.0.88\nSuccessfully installed opencv-python-headless-4.13.0.90\nCreating new Ultralytics Settings v0.0.6 file ‚úÖ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n‚úì Ultralytics installed successfully!\n","output_type":"stream"}],"execution_count":2},{"id":"14eb584c","cell_type":"markdown","source":"## Step 2: Dataset Preparation","metadata":{}},{"id":"1cbec1bc","cell_type":"code","source":"import os\nimport json\nimport shutil\nfrom pathlib import Path\n\n# Kaggle dataset paths\nKAGGLE_INPUT = '/kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset'\n\n# Check if dataset exists\nif os.path.exists(KAGGLE_INPUT):\n    print(\"‚úì Dataset found!\")\n    print(\"\\nDataset structure:\")\n    for root, dirs, files in os.walk(KAGGLE_INPUT):\n        level = root.replace(KAGGLE_INPUT, '').count(os.sep)\n        indent = ' ' * 2 * level\n        print(f'{indent}{os.path.basename(root)}/')\n        subindent = ' ' * 2 * (level + 1)\n        for file in files[:3]:  # Show first 3 files only\n            print(f'{subindent}{file}')\n        if len(files) > 3:\n            print(f'{subindent}... and {len(files)-3} more files')\n        if level > 2:  # Limit depth\n            break\nelse:\n    print(\"‚ùå Dataset not found!\")\n    print(\"Please add the dataset: https://www.kaggle.com/datasets/prosenjitmondol/complete-vindr-spinexr\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:06:16.632651Z","iopub.execute_input":"2026-01-23T12:06:16.633508Z","iopub.status.idle":"2026-01-23T12:06:52.370933Z","shell.execute_reply.started":"2026-01-23T12:06:16.633476Z","shell.execute_reply":"2026-01-23T12:06:52.370259Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"‚úì Dataset found!\n\nDataset structure:\nvindr-spinexr-a-large-annotated-medical-image-dataset/\n  vindr-spinexr-a-large-annotated-medical-image-dataset/\n    SHA256SUMS.txt\n    train_meta.csv\n    test_meta.csv\n    ... and 2 more files\n    train_png/\n      603991895639eb7b33bf9475b9b7d719.png\n      7f9faef52144cb53e35c0b60d6156d05.png\n      ed2eb4eee981d1814ab6daff44773ad9.png\n      ... and 8159 more files\n    train_images/\n      9e20054e418c7497cc590c345557f497.dicom\n      0ad3d2bf7e1b745151dc4b0f9ddbf96a.dicom\n      bd317694f1b3775fe67f0c641a8a1ba5.dicom\n      ... and 8386 more files\n    test_png/\n      f330e28213fe142f0cf8a158fe171282.png\n      c4ed963e96cfd445e7eb120066f63a16.png\n      bb5c63def3833b9a2c716fbdb083b7a6.png\n      ... and 2074 more files\n    annotations/\n      train.csv\n      test.csv\n    test_images/\n      e879dd6f41cb5909448dc52968d8b690.dicom\n      97001c74dbddbb2d279a18752337814b.dicom\n      6df4ca68b4e0a57f5b9f43a9cb4e2136.dicom\n      ... and 2074 more files\n","output_type":"stream"}],"execution_count":3},{"id":"014e651c","cell_type":"code","source":"# Create YOLO format dataset structure\nWORK_DIR = '/kaggle/working'\nDATASET_DIR = f'{WORK_DIR}/vindr_yolo'\n\n# Create directories\nos.makedirs(f'{DATASET_DIR}/images/train', exist_ok=True)\nos.makedirs(f'{DATASET_DIR}/images/val', exist_ok=True)\nos.makedirs(f'{DATASET_DIR}/labels/train', exist_ok=True)\nos.makedirs(f'{DATASET_DIR}/labels/val', exist_ok=True)\n\nprint(\"‚úì Directory structure created\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:06:52.372510Z","iopub.execute_input":"2026-01-23T12:06:52.372795Z","iopub.status.idle":"2026-01-23T12:06:52.378546Z","shell.execute_reply.started":"2026-01-23T12:06:52.372772Z","shell.execute_reply":"2026-01-23T12:06:52.377869Z"}},"outputs":[{"name":"stdout","text":"‚úì Directory structure created\n","output_type":"stream"}],"execution_count":4},{"id":"d749f620","cell_type":"markdown","source":"## Step 3: Convert COCO to YOLO Format","metadata":{}},{"id":"e8708e7e","cell_type":"code","source":"def coco_to_yolo(coco_json_path, images_dir, output_labels_dir, output_images_dir):\n    \"\"\"\n    Convert COCO format annotations to YOLO format\n    \"\"\"\n    print(f\"Converting {coco_json_path}...\")\n    \n    with open(coco_json_path, 'r') as f:\n        coco_data = json.load(f)\n    \n    # Build image info dict\n    images_info = {img['id']: img for img in coco_data['images']}\n    \n    # Build category mapping (COCO uses 1-indexed, YOLO uses 0-indexed)\n    category_mapping = {cat['id']: idx for idx, cat in enumerate(coco_data['categories'])}\n    \n    # Group annotations by image_id\n    annotations_by_image = {}\n    for ann in coco_data['annotations']:\n        img_id = ann['image_id']\n        if img_id not in annotations_by_image:\n            annotations_by_image[img_id] = []\n        annotations_by_image[img_id].append(ann)\n    \n    converted_count = 0\n    skipped_count = 0\n    \n    for img_id, img_info in images_info.items():\n        file_name = img_info['file_name']\n        img_width = img_info['width']\n        img_height = img_info['height']\n        \n        # Check for PNG version (train_png/test_png)\n        img_name_base = os.path.splitext(file_name)[0]\n        src_image_path = os.path.join(images_dir, f'{img_name_base}.png')\n        \n        # Fallback to original if PNG doesn't exist\n        if not os.path.exists(src_image_path):\n            src_image_path = os.path.join(images_dir.replace('_png', '_images'), file_name)\n        \n        if not os.path.exists(src_image_path):\n            skipped_count += 1\n            continue\n        \n        # Copy image\n        dst_image_path = os.path.join(output_images_dir, f'{img_name_base}.png')\n        if not os.path.exists(dst_image_path):\n            shutil.copy2(src_image_path, dst_image_path)\n        \n        # Convert annotations to YOLO format\n        yolo_annotations = []\n        if img_id in annotations_by_image:\n            for ann in annotations_by_image[img_id]:\n                category_id = category_mapping[ann['category_id']]\n                bbox = ann['bbox']  # [x, y, width, height] in COCO\n                \n                # Convert to YOLO format: [class, x_center, y_center, width, height] (normalized)\n                x_center = (bbox[0] + bbox[2] / 2) / img_width\n                y_center = (bbox[1] + bbox[3] / 2) / img_height\n                width = bbox[2] / img_width\n                height = bbox[3] / img_height\n                \n                yolo_annotations.append(f\"{category_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n        \n        # Write YOLO label file\n        label_path = os.path.join(output_labels_dir, f'{img_name_base}.txt')\n        with open(label_path, 'w') as f:\n            f.write('\\n'.join(yolo_annotations))\n        \n        converted_count += 1\n        if converted_count % 1000 == 0:\n            print(f\"  Converted {converted_count} images...\")\n    \n    print(f\"‚úì Converted {converted_count} images\")\n    if skipped_count > 0:\n        print(f\"‚ö† Skipped {skipped_count} images (not found)\")\n    \n    return converted_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:06:52.379480Z","iopub.execute_input":"2026-01-23T12:06:52.379820Z","iopub.status.idle":"2026-01-23T12:06:52.398133Z","shell.execute_reply.started":"2026-01-23T12:06:52.379783Z","shell.execute_reply":"2026-01-23T12:06:52.397470Z"}},"outputs":[],"execution_count":5},{"id":"96dbe089","cell_type":"code","source":"# Convert training data\n# Based on actual Kaggle dataset structure from screenshot\nimport glob\n\n# Correct paths from your Kaggle dataset structure\ntrain_json = '/kaggle/input/complete-vindr-spinexr/coco format/train_coco.json'\ntrain_images = '/kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset/vindr-spinexr-a-large-annotated-medical-image-dataset/train_png'\n\nprint(\"Checking training dataset paths...\")\nprint(f\"JSON: {train_json}\")\nprint(f\"Images: {train_images}\")\n\n# Verify paths exist\nif not os.path.exists(train_json):\n    print(f\"‚ùå ERROR: JSON not found at {train_json}\")\n    train_count = 0\nelif not os.path.exists(train_images):\n    print(f\"‚ùå ERROR: Images folder not found at {train_images}\")\n    train_count = 0\nelse:\n    # Count images\n    sample_files = glob.glob(os.path.join(train_images, '*.png'))\n    print(f\"‚úì Found {len(sample_files)} PNG files\\n\")\n    \n    # Convert\n    train_count = coco_to_yolo(\n        train_json,\n        train_images,\n        f'{DATASET_DIR}/labels/train',\n        f'{DATASET_DIR}/images/train'\n    )\n    print(f\"\\n‚úì Total training images converted: {train_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:06:52.398966Z","iopub.execute_input":"2026-01-23T12:06:52.399235Z","iopub.status.idle":"2026-01-23T12:11:00.580221Z","shell.execute_reply.started":"2026-01-23T12:06:52.399203Z","shell.execute_reply":"2026-01-23T12:11:00.579446Z"}},"outputs":[{"name":"stdout","text":"Checking training dataset paths...\nJSON: /kaggle/input/complete-vindr-spinexr/coco format/train_coco.json\nImages: /kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset/vindr-spinexr-a-large-annotated-medical-image-dataset/train_png\n‚úì Found 8162 PNG files\n\nConverting /kaggle/input/complete-vindr-spinexr/coco format/train_coco.json...\n  Converted 1000 images...\n  Converted 2000 images...\n  Converted 3000 images...\n  Converted 4000 images...\n  Converted 5000 images...\n  Converted 6000 images...\n  Converted 7000 images...\n  Converted 8000 images...\n‚úì Converted 8162 images\n‚ö† Skipped 227 images (not found)\n\n‚úì Total training images converted: 8162\n","output_type":"stream"}],"execution_count":6},{"id":"7a6a39e0","cell_type":"code","source":"# Convert validation/test data\n# Based on actual Kaggle dataset structure\nval_json = '/kaggle/input/complete-vindr-spinexr/coco format/test_coco.json'\nval_images = '/kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset/vindr-spinexr-a-large-annotated-medical-image-dataset/test_png'\n\nprint(\"Checking validation dataset paths...\")\nprint(f\"JSON: {val_json}\")\nprint(f\"Images: {val_images}\")\n\n# Verify paths exist\nif not os.path.exists(val_json):\n    print(f\"‚ùå ERROR: JSON not found at {val_json}\")\n    val_count = 0\nelif not os.path.exists(val_images):\n    print(f\"‚ùå ERROR: Images folder not found at {val_images}\")\n    val_count = 0\nelse:\n    # Count images\n    sample_files = glob.glob(os.path.join(val_images, '*.png'))\n    print(f\"‚úì Found {len(sample_files)} PNG files\\n\")\n    \n    # Convert\n    val_count = coco_to_yolo(\n        val_json,\n        val_images,\n        f'{DATASET_DIR}/labels/val',\n        f'{DATASET_DIR}/images/val'\n    )\n    print(f\"\\n‚úì Total validation images converted: {val_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:11:00.581447Z","iopub.execute_input":"2026-01-23T12:11:00.581763Z","iopub.status.idle":"2026-01-23T12:12:04.723938Z","shell.execute_reply.started":"2026-01-23T12:11:00.581734Z","shell.execute_reply":"2026-01-23T12:12:04.723237Z"}},"outputs":[{"name":"stdout","text":"Checking validation dataset paths...\nJSON: /kaggle/input/complete-vindr-spinexr/coco format/test_coco.json\nImages: /kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset/vindr-spinexr-a-large-annotated-medical-image-dataset/test_png\n‚úì Found 2077 PNG files\n\nConverting /kaggle/input/complete-vindr-spinexr/coco format/test_coco.json...\n  Converted 1000 images...\n  Converted 2000 images...\n‚úì Converted 2077 images\n\n‚úì Total validation images converted: 2077\n","output_type":"stream"}],"execution_count":7},{"id":"2d567253","cell_type":"markdown","source":"## Step 4: Create YAML Configuration","metadata":{}},{"id":"36f1b518","cell_type":"code","source":"# Create dataset YAML file\nyaml_content = f\"\"\"# VinDr-SpineXR Dataset Configuration for YOLO11-x\n\npath: {DATASET_DIR}\ntrain: images/train\nval: images/val\n\n# Number of classes\nnc: 7\n\n# Class names\nnames:\n  0: Osteophytes\n  1: Surgical implant\n  2: Spondylolysthesis\n  3: Foraminal stenosis\n  4: Disc space narrowing\n  5: Vertebral collapse\n  6: Other lesions\n\"\"\"\n\nyaml_path = f'{WORK_DIR}/vindr_spinexr.yaml'\nwith open(yaml_path, 'w') as f:\n    f.write(yaml_content)\n\nprint(\"‚úì Dataset YAML created\")\nprint(f\"\\nConfiguration saved to: {yaml_path}\")\nprint(\"\\nContents:\")\nprint(yaml_content)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:12:04.724924Z","iopub.execute_input":"2026-01-23T12:12:04.725214Z","iopub.status.idle":"2026-01-23T12:12:04.730561Z","shell.execute_reply.started":"2026-01-23T12:12:04.725189Z","shell.execute_reply":"2026-01-23T12:12:04.729959Z"}},"outputs":[{"name":"stdout","text":"‚úì Dataset YAML created\n\nConfiguration saved to: /kaggle/working/vindr_spinexr.yaml\n\nContents:\n# VinDr-SpineXR Dataset Configuration for YOLO11-x\n\npath: /kaggle/working/vindr_yolo\ntrain: images/train\nval: images/val\n\n# Number of classes\nnc: 7\n\n# Class names\nnames:\n  0: Osteophytes\n  1: Surgical implant\n  2: Spondylolysthesis\n  3: Foraminal stenosis\n  4: Disc space narrowing\n  5: Vertebral collapse\n  6: Other lesions\n\n","output_type":"stream"}],"execution_count":8},{"id":"2d0b438d","cell_type":"markdown","source":"## Step 5: Load YOLO11-x Model","metadata":{}},{"id":"6bef6793","cell_type":"code","source":"print(\"=\"*80)\nprint(\"LOADING YOLO11-x MODEL\")\nprint(\"=\"*80)\n\n# Load YOLO11-x with COCO pretrained weights\nmodel = YOLO('yolo11x.pt')  # Auto-downloads ~140MB\n\nprint(\"\\n‚úì YOLO11-x loaded successfully!\")\nprint(f\"\\nModel Details:\")\nprint(f\"  Parameters: ~65M\")\nprint(f\"  Architecture: YOLO11-x\")\nprint(f\"  Pretrained: COCO dataset\")\nprint(f\"  Input size: 640√ó640\")\nprint(f\"\\nExpected Performance:\")\nprint(f\"  mAP@0.5: 35-39% (vs 32-36% with YOLO11-l)\")\nprint(f\"  Training time: ~10-12 hours on Kaggle GPU\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:12:04.731435Z","iopub.execute_input":"2026-01-23T12:12:04.731637Z","iopub.status.idle":"2026-01-23T12:12:06.799583Z","shell.execute_reply.started":"2026-01-23T12:12:04.731617Z","shell.execute_reply":"2026-01-23T12:12:06.798962Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nLOADING YOLO11-x MODEL\n================================================================================\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo11x.pt to 'yolo11x.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 109.3MB 195.0MB/s 0.6s0.5s<0.1s\n\n‚úì YOLO11-x loaded successfully!\n\nModel Details:\n  Parameters: ~65M\n  Architecture: YOLO11-x\n  Pretrained: COCO dataset\n  Input size: 640√ó640\n\nExpected Performance:\n  mAP@0.5: 35-39% (vs 32-36% with YOLO11-l)\n  Training time: ~10-12 hours on Kaggle GPU\n","output_type":"stream"}],"execution_count":9},{"id":"d9227a34","cell_type":"markdown","source":"## Step 6: Configure Training Parameters","metadata":{}},{"id":"ef2cfedb","cell_type":"code","source":"# Training configuration optimized for Kaggle GPU (16GB)\nEPOCHS = 30  # Reduced from 35 to fit within 12-hour limit safely\nBATCH_SIZE = 8  # YOLO11-x with 16GB GPU (vs batch=12 for YOLO11-l)\nIMG_SIZE = 640\nDEVICE = 0\n\nprint(\"Training Configuration:\")\nprint(f\"  Model: YOLO11-x (65M parameters)\")\nprint(f\"  Epochs: {EPOCHS}\")\nprint(f\"  Batch Size: {BATCH_SIZE}\")\nprint(f\"  Image Size: {IMG_SIZE}√ó{IMG_SIZE}\")\nprint(f\"  Device: GPU {DEVICE if torch.cuda.is_available() else 'CPU'}\")\nprint(f\"\\nDataset Characteristics:\")\nprint(f\"  Training images: {train_count}\")\nprint(f\"  Validation images: {val_count}\")\nprint(f\"  Classes: 7 lesion types\")\nprint(f\"  Class imbalance: ~46.9:1 (Osteophytes vs Vertebral collapse)\")\nprint(f\"\\nOptimizations:\")\nprint(f\"  - Focal Loss (handles class imbalance)\")\nprint(f\"  - Copy-paste augmentation (20%)\")\nprint(f\"  - Multi-scale detection (P3-P5)\")\nprint(f\"  - Mixed precision training (AMP)\")\nprint(f\"  - Cosine learning rate schedule\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:12:06.801875Z","iopub.execute_input":"2026-01-23T12:12:06.802098Z","iopub.status.idle":"2026-01-23T12:12:06.808062Z","shell.execute_reply.started":"2026-01-23T12:12:06.802075Z","shell.execute_reply":"2026-01-23T12:12:06.807456Z"}},"outputs":[{"name":"stdout","text":"Training Configuration:\n  Model: YOLO11-x (65M parameters)\n  Epochs: 30\n  Batch Size: 8\n  Image Size: 640√ó640\n  Device: GPU 0\n\nDataset Characteristics:\n  Training images: 8162\n  Validation images: 2077\n  Classes: 7 lesion types\n  Class imbalance: ~46.9:1 (Osteophytes vs Vertebral collapse)\n\nOptimizations:\n  - Focal Loss (handles class imbalance)\n  - Copy-paste augmentation (20%)\n  - Multi-scale detection (P3-P5)\n  - Mixed precision training (AMP)\n  - Cosine learning rate schedule\n","output_type":"stream"}],"execution_count":10},{"id":"4e2999e2","cell_type":"markdown","source":"## Step 6.5: Check for Previous Training & Auto-Resume","metadata":{}},{"id":"868b8ef2","cell_type":"code","source":"import os\nimport glob\n\n# Check for existing training runs\nCHECKPOINT_DIR = 'runs/yolo11x/vindr_spinexr'\nRESUME_CHECKPOINT = None\n\nprint(\"=\" * 80)\nprint(\"CHECKPOINT DETECTION\")\nprint(\"=\" * 80)\n\nif os.path.exists(CHECKPOINT_DIR):\n    # Check for last.pt (most recent checkpoint)\n    last_checkpoint = os.path.join(CHECKPOINT_DIR, 'weights', 'last.pt')\n    \n    if os.path.exists(last_checkpoint):\n        print(f\"\\n‚úì Found previous training checkpoint!\")\n        print(f\"  Location: {last_checkpoint}\")\n        \n        # Try to read epoch info from results.csv\n        results_csv = os.path.join(CHECKPOINT_DIR, 'results.csv')\n        if os.path.exists(results_csv):\n            import pandas as pd\n            df = pd.read_csv(results_csv)\n            last_epoch = len(df)\n            print(f\"  Last completed epoch: {last_epoch}/{EPOCHS}\")\n            print(f\"  Remaining epochs: {EPOCHS - last_epoch}\")\n            \n            if last_epoch >= EPOCHS:\n                print(f\"\\n‚ö†Ô∏è  Training already completed!\")\n                print(f\"  To start fresh, delete: {CHECKPOINT_DIR}\")\n            else:\n                print(f\"\\n‚úÖ Will RESUME training from epoch {last_epoch + 1}\")\n                RESUME_CHECKPOINT = last_checkpoint\n        else:\n            print(f\"\\n‚úÖ Will RESUME training from last checkpoint\")\n            RESUME_CHECKPOINT = last_checkpoint\n    else:\n        print(\"\\nNo checkpoint found. Starting fresh training.\")\nelse:\n    print(\"\\nNo previous training found. Starting fresh training.\")\n\nprint(\"\\n\" + \"=\" * 80)\n\n# Summary\nif RESUME_CHECKPOINT:\n    print(f\"\\nüîÑ RESUME MODE: Training will continue from last checkpoint\")\n    print(f\"   Checkpoint: {RESUME_CHECKPOINT}\")\nelse:\n    print(f\"\\nüÜï FRESH START: Training will begin from epoch 1\")\n    print(f\"   Checkpoints will be saved every 5 epochs\")\n\nprint(\"\\n\" + \"=\" * 80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:12:06.809130Z","iopub.execute_input":"2026-01-23T12:12:06.809335Z","iopub.status.idle":"2026-01-23T12:12:06.825186Z","shell.execute_reply.started":"2026-01-23T12:12:06.809315Z","shell.execute_reply":"2026-01-23T12:12:06.824593Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nCHECKPOINT DETECTION\n================================================================================\n\nNo previous training found. Starting fresh training.\n\n================================================================================\n\nüÜï FRESH START: Training will begin from epoch 1\n   Checkpoints will be saved every 5 epochs\n\n================================================================================\n","output_type":"stream"}],"execution_count":11},{"id":"67f2ad62","cell_type":"code","source":"# IMPORTANT: Setup auto-backup to prevent data loss\nimport shutil\nfrom pathlib import Path\n\nBACKUP_DIR = '/kaggle/working/backup_checkpoints'\nos.makedirs(BACKUP_DIR, exist_ok=True)\n\nprint(\"=\" * 80)\nprint(\"BACKUP SYSTEM ACTIVATED\")\nprint(\"=\" * 80)\nprint(\"\\n‚ö†Ô∏è  IMPORTANT: To save your training progress:\")\nprint(\"   1. Training checkpoints auto-save to: runs/yolo11x/vindr_spinexr/weights/\")\nprint(\"   2. After training completes or periodically:\")\nprint(\"      - Go to 'Output' tab in Kaggle\")\nprint(\"      - Click 'Save Version' to preserve files\")\nprint(\"   3. Or download files manually during training\")\nprint(\"\\nüí° TIP: Enable 'Version Settings' > 'Always Save Output' in notebook settings\")\nprint(\"=\" * 80 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:12:06.826108Z","iopub.execute_input":"2026-01-23T12:12:06.826337Z","iopub.status.idle":"2026-01-23T12:12:06.844168Z","shell.execute_reply.started":"2026-01-23T12:12:06.826315Z","shell.execute_reply":"2026-01-23T12:12:06.843656Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nBACKUP SYSTEM ACTIVATED\n================================================================================\n\n‚ö†Ô∏è  IMPORTANT: To save your training progress:\n   1. Training checkpoints auto-save to: runs/yolo11x/vindr_spinexr/weights/\n   2. After training completes or periodically:\n      - Go to 'Output' tab in Kaggle\n      - Click 'Save Version' to preserve files\n   3. Or download files manually during training\n\nüí° TIP: Enable 'Version Settings' > 'Always Save Output' in notebook settings\n================================================================================\n\n","output_type":"stream"}],"execution_count":12},{"id":"c21a14b8","cell_type":"markdown","source":"## Step 7: Train YOLO11-x","metadata":{}},{"id":"8f2ec3af","cell_type":"code","source":"print(\"=\"*80)\nprint(\"STARTING TRAINING - YOLO11-x ON VinDr-SpineXR\")\nprint(\"=\"*80)\n\n# Determine if resuming or starting fresh\nif RESUME_CHECKPOINT:\n    print(f\"\\nüîÑ RESUMING from checkpoint: {RESUME_CHECKPOINT}\")\n    print(\"Previous training progress will continue...\")\nelse:\n    print(\"\\nüÜï STARTING FRESH training\")\n    \nprint(\"\\nEstimated time: 10-12 hours\")\nprint(\"This cell will run continuously. Monitor progress below.\")\nprint(\"\\nüíæ Auto-save: Checkpoints saved every 5 epochs\")\nprint(\"‚ö†Ô∏è  Kaggle limit: 12-hour session (training will complete in time)\")\nprint(\"üîÑ If interrupted: Re-run notebook to auto-resume\\n\")\n\n# Train the model (with resume support)\nresults = model.train(\n    data=yaml_path,\n    epochs=EPOCHS,\n    batch=BATCH_SIZE,\n    imgsz=IMG_SIZE,\n    device=DEVICE,\n    resume=bool(RESUME_CHECKPOINT),  # Auto-resume if checkpoint exists\n    \n    # Optimizer settings\n    optimizer='AdamW',\n    lr0=0.0001,           # Initial learning rate\n    lrf=0.01,             # Final LR = lr0 * lrf\n    momentum=0.937,\n    weight_decay=0.0005,\n    warmup_epochs=3,\n    warmup_momentum=0.8,\n    warmup_bias_lr=0.1,\n    \n    # Loss weights (optimized for small objects + class imbalance)\n    box=7.5,              # Box loss weight\n    cls=0.5,              # Classification loss (focal loss handles imbalance)\n    dfl=1.5,              # Distribution focal loss\n    \n    # Data augmentation (optimized for medical imaging)\n    hsv_h=0.015,          # Hue augmentation (conservative for medical)\n    hsv_s=0.7,            # Saturation\n    hsv_v=0.4,            # Brightness\n    degrees=5.0,          # Rotation ¬±5¬∞\n    translate=0.1,        # Translation\n    scale=0.5,            # Scale variation (0.5-1.5x)\n    shear=0.0,            # No shear (too slow)\n    perspective=0.0,      # No perspective (too slow)\n    flipud=0.5,           # Vertical flip (spine X-rays)\n    fliplr=0.5,           # Horizontal flip\n    \n    # Copy-paste for minority classes (CRITICAL)\n    copy_paste=0.2,       # 20% copy-paste augmentation\n    \n    # Mosaic augmentation\n    mosaic=1.0,           # Enable mosaic (multi-scale learning)\n    mixup=0.0,            # Disable mixup (too slow)\n    \n    # Multi-scale training\n    multi_scale=False,    # Disable for speed (mosaic provides similar benefit)\n    \n    # Training schedule\n    patience=20,          # Early stopping patience\n    save=True,\n    save_period=5,        # Save checkpoint every 5 epochs (was 10, now more frequent for safety)\n    cache=False,          # Don't cache (large dataset)\n    workers=8,            # Dataloader workers (Kaggle has good CPU)\n    \n    # Output settings\n    project='runs/yolo11x',\n    name='vindr_spinexr',\n    exist_ok=True,\n    pretrained=True,      # Use COCO pretrained weights\n    verbose=True,\n    seed=42,\n    deterministic=False,\n    single_cls=False,\n    \n    # Learning rate scheduler\n    cos_lr=True,          # Cosine LR decay\n    close_mosaic=5,       # Disable mosaic last 5 epochs\n    \n    # Mixed precision (faster + less memory)\n    amp=True,             # Automatic Mixed Precision\n    \n    # Validation\n    val=True,\n    plots=True,\n    \n    # Image handling\n    rect=False,           # Square images for multi-scale\n    \n    # Regularization\n    dropout=0.1,\n    label_smoothing=0.0,  # Disabled for medical (hard labels)\n    \n    # NMS settings\n    iou=0.7,\n    max_det=300,\n)\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"TRAINING COMPLETED!\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T12:12:06.845115Z","iopub.execute_input":"2026-01-23T12:12:06.845406Z","iopub.status.idle":"2026-01-23T17:44:24.331029Z","shell.execute_reply.started":"2026-01-23T12:12:06.845371Z","shell.execute_reply":"2026-01-23T17:44:24.309860Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nSTARTING TRAINING - YOLO11-x ON VinDr-SpineXR\n================================================================================\n\nüÜï STARTING FRESH training\n\nEstimated time: 10-12 hours\nThis cell will run continuously. Monitor progress below.\n\nüíæ Auto-save: Checkpoints saved every 5 epochs\n‚ö†Ô∏è  Kaggle limit: 12-hour session (training will complete in time)\nüîÑ If interrupted: Re-run notebook to auto-resume\n\nWARNING ‚ö†Ô∏è 'label_smoothing' is deprecated and will be removed in the future.\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, angle=1.0, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=5, cls=0.5, compile=False, conf=None, copy_paste=0.2, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=/kaggle/working/vindr_spinexr.yaml, degrees=5.0, deterministic=False, device=0, dfl=1.5, dnn=False, dropout=0.1, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.5, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=vindr_spinexr, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/yolo11x, rect=False, resume=False, retina_masks=False, rle=1.0, save=True, save_conf=False, save_crop=False, save_dir=/kaggle/working/runs/detect/runs/yolo11x/vindr_spinexr, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=42, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 755.1KB 14.2MB/s 0.1s\nOverriding model.yaml nc=80 with nc=7\n\n                   from  n    params  module                                       arguments                     \n  0                  -1  1      2784  ultralytics.nn.modules.conv.Conv             [3, 96, 3, 2]                 \n  1                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n  2                  -1  2    389760  ultralytics.nn.modules.block.C3k2            [192, 384, 2, True, 0.25]     \n  3                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n  4                  -1  2   1553664  ultralytics.nn.modules.block.C3k2            [384, 768, 2, True, 0.25]     \n  5                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n  6                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n  7                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n  8                  -1  2   5022720  ultralytics.nn.modules.block.C3k2            [768, 768, 2, True]           \n  9                  -1  1   1476864  ultralytics.nn.modules.block.SPPF            [768, 768, 5]                 \n 10                  -1  2   3264768  ultralytics.nn.modules.block.C2PSA           [768, 768, 2]                 \n 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 13                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 16                  -1  2   1700352  ultralytics.nn.modules.block.C3k2            [1536, 384, 2, True]          \n 17                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 19                  -1  2   5317632  ultralytics.nn.modules.block.C3k2            [1152, 768, 2, True]          \n 20                  -1  1   5309952  ultralytics.nn.modules.conv.Conv             [768, 768, 3, 2]              \n 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n 22                  -1  2   5612544  ultralytics.nn.modules.block.C3k2            [1536, 768, 2, True]          \n 23        [16, 19, 22]  1   3153637  ultralytics.nn.modules.head.Detect           [7, 16, None, [384, 768, 768]]\nYOLO11x summary: 358 layers, 56,881,861 parameters, 56,881,845 gradients, 195.5 GFLOPs\n\nTransferred 1009/1015 items from pretrained weights\nFreezing layer 'model.23.dfl.conv.weight'\n\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.4.0/yolo26n.pt to 'yolo26n.pt': 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 5.3MB 53.2MB/s 0.1s\n\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ‚úÖ\n\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 737.3¬±1536.1 MB/s, size: 1371.6 KB)\n\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/working/vindr_yolo/labels/train... 8162 images, 4140 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8162/8162 107.2it/s 1:16<0.1ss\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/00fcfd1e6410590c9a6b2b498458fad7.png: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/08624dbb49f9c64098714416a1532139.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/0b8c137ee0de66aadfd5ea250be1762b.png: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/0edea499775325bb4eeac1774cbec784.png: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/1da99ed64919a77e121087436b95a40c.png: 7 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/1e3abd720ddde603be711dd5e628921f.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/27eba2767f7dd6cbd9881bddbbd6b562.png: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/286c5f0677f222eb0d5b2d5ac3b16e37.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/29779466726dbd2c3fb3c98e4de38c11.png: 6 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/3681554f72ccf1ece98817867b43cb26.png: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/3c227fd84ec22e03a967b7b67ce61aa6.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/4ad823a65ee51865f625b77a3e4f1bf7.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/5811869863092b5501c7ce582a49a1d3.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/5848745804ce2d939308b6b033e72913.png: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/6290bb6fecfa32e516eda74e1f9a03aa.png: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/631d45620e593b2d66fee853ef36dbbf.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/727f69e517aad0aaed7eb00058beea08.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/799aca17810caee870cf3facd771b6ac.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/7c0e490da71a242044556441d7df1e4c.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/88d1cfb8e65038d6e2a9c4a9da8befef.png: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/94ca0f13ee386331e192730881702047.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/94cb4561e5a8df4decda5d22a64aba91.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/99550d6db73b9f6097686efff87d7e17.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/a945e4d338b1e7bf237e8a48fca331bb.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/adc3494fb5135f8ad0a13b53c5b1a940.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/ba0aecfb46d044ef1d4f5372f92e38e8.png: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/c18825a09aa0c6ee040909a0a41f6a6d.png: 3 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/c3b0d5f2bcf9f78fb447d5aa7afa34b1.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/cba809426ac18160b3475922828ea357.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/cf77d12ad9f7f99a70c7f7eff2344c0c.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/d49eb7878cf0bbdaefe1c7ee3b51abd6.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/d5fcd98c85c4eb14dd6dccd0ec9af94e.png: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/d9592ec35f8ba8355404a4d70079a38e.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/db891d3f337735034fc12d76fefa3397.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/e9f0d9c76e37acf68926ceb532b9213f.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/f0324729a12f7a160c1aba98bfd7269d.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/f93faaeca0f037964e58f9ddd369fd07.png: 4 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0m/kaggle/working/vindr_yolo/images/train/fe7993d6b62c4dd63c07160a36e89db9.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /kaggle/working/vindr_yolo/labels/train.cache\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\u001b[34m\u001b[1mval: \u001b[0mFast image access ‚úÖ (ping: 0.0¬±0.0 ms, read: 159.8¬±11.9 MB/s, size: 1722.8 KB)\n\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/working/vindr_yolo/labels/val... 2077 images, 1070 backgrounds, 0 corrupt: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 2077/2077 110.6it/s 18.8s<0.1s\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/078075701bb83b1ac2f833c0576a33fd.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/0881a2daafeb7f9514bd038be28e1731.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/0ccf49e003ad267062de0c14bb4d4088.png: 4 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/0eb0109248f23d97ef84f69550e3904c.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/17994fef8a7b911ee5e3575fe5b6460f.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/2e98d68eb858603f49f9c6185a0fa333.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/3f503dc886d4105b86e199f6ef3bd722.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/42ac803c392ced8602375ce02e91e842.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/581551b9b2437845bce6984747f01a00.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/5d699eae50ae88bb7294742520b460ac.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/73297e7a2151c3f0ca1c8ea533dccccc.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/85b083ac5488c1e4592db7857c12aba7.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/9f982b9f2cf9e2a80492662613425c62.png: 4 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/c25d0e4f70c6724041b984e350c92882.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/d3ac3d1f5891423fed5ea5a69c382a5a.png: 5 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/dccb34a2097d5c5c91381487a9f6ad5a.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/e01ecc73a2a3103e10a7758467345bfc.png: 2 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/e4680769569ca93d8f0601f7b9ba0c7e.png: 1 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0m/kaggle/working/vindr_yolo/images/val/f24a26d36bdeee4ab2459039567bf05d.png: 4 duplicate labels removed\n\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /kaggle/working/vindr_yolo/labels/val.cache\nPlotting labels to /kaggle/working/runs/detect/runs/yolo11x/vindr_spinexr/labels.jpg... \n\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0005), 173 bias(decay=0.0)\nImage sizes 640 train, 640 val\nUsing 2 dataloader workers\nLogging results to \u001b[1m/kaggle/working/runs/detect/runs/yolo11x/vindr_spinexr\u001b[0m\nStarting training for 30 epochs...\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       1/30      8.01G      2.647      2.959      1.515          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.6it/s 10:35<0.8s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 1.6it/s 1:190.3ss\n                   all       2077       3638       0.54       0.12     0.0926     0.0421\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       2/30      8.59G      2.415      2.505      1.408         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:08<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.8s0.3s\n                   all       2077       3638      0.395      0.202      0.143     0.0628\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       3/30       8.6G      2.341      2.329      1.362          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:05<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.4it/s 53.5s0.3s\n                   all       2077       3638      0.358      0.219      0.152     0.0622\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       4/30      8.55G      2.302      2.274      1.351         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 50.7s0.3s\n                   all       2077       3638      0.514      0.224      0.188      0.084\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       5/30      8.58G      2.279      2.177       1.32          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.5s0.3s\n                   all       2077       3638      0.436      0.252      0.224     0.0972\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       6/30      8.59G      2.249      2.123      1.313          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.4s0.3s\n                   all       2077       3638      0.466      0.252      0.257      0.114\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       7/30      8.58G      2.232      2.071      1.302          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:03<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.8s0.3s\n                   all       2077       3638      0.319      0.302      0.254      0.109\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       8/30      8.55G      2.208      2.049      1.299          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:03<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.3s0.3s\n                   all       2077       3638      0.479      0.304      0.282      0.123\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K       9/30      8.61G      2.186      2.035      1.286          4        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:03<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.7it/s 48.6s0.3s\n                   all       2077       3638      0.448      0.306      0.273      0.116\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      10/30      8.59G      2.162       2.01      1.271          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:03<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.1s0.3s\n                   all       2077       3638      0.507      0.354      0.307      0.141\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      11/30      8.58G      2.143      1.983      1.281         20        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:03<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.1s0.3s\n                   all       2077       3638      0.431      0.347      0.322      0.146\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      12/30      8.48G      2.142      1.997      1.277          8        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.3s0.3s\n                   all       2077       3638       0.51      0.376      0.324      0.149\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      13/30      8.59G      2.112      1.922      1.254         16        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.7it/s 49.0s0.3s\n                   all       2077       3638      0.498      0.389      0.346      0.153\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      14/30      8.58G      2.097      1.889      1.254          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.4s0.2s\n                   all       2077       3638      0.335      0.371      0.305      0.137\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      15/30      8.67G      2.099      1.874      1.249         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.7it/s 49.0s0.3s\n                   all       2077       3638      0.377      0.374      0.336      0.151\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      16/30      8.56G      2.095      1.885      1.248          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.7it/s 48.7s0.3s\n                   all       2077       3638      0.362      0.376      0.331      0.153\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      17/30       8.6G      2.075       1.85       1.25          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.2s0.3s\n                   all       2077       3638      0.352      0.398      0.339      0.154\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      18/30      8.59G      2.069      1.821      1.237          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 50.5s0.3s\n                   all       2077       3638      0.349      0.399      0.343      0.162\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      19/30       8.6G      2.056      1.816      1.225          5        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.4s0.3s\n                   all       2077       3638      0.353      0.435      0.367      0.174\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      20/30      8.49G      2.038      1.776      1.242          6        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.2s0.2s\n                   all       2077       3638       0.39      0.408      0.368      0.165\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      21/30      8.57G       2.02      1.747      1.215          1        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:05<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.4s0.3s\n                   all       2077       3638      0.387       0.42      0.391      0.181\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      22/30      8.58G      2.022      1.736      1.222         15        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.4s0.3s\n                   all       2077       3638      0.403      0.428      0.376       0.18\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      23/30      8.33G      2.013       1.71       1.21          7        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.1s0.2s\n                   all       2077       3638      0.392      0.421      0.376      0.176\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      24/30      8.32G       2.01      1.708      1.218         11        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.7s0.3s\n                   all       2077       3638      0.378      0.421      0.372      0.173\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      25/30      8.59G      1.997      1.723      1.207          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.3s0.3s\n                   all       2077       3638      0.408      0.403      0.384      0.179\nClosing dataloader mosaic\n\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      26/30       8.6G      1.981      1.741      1.229          0        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:05<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.5s0.3s\n                   all       2077       3638      0.385      0.414      0.378      0.174\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      27/30      8.59G      1.993      1.741      1.233         12        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.4s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 49.7s0.3s\n                   all       2077       3638      0.375      0.427       0.38      0.177\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      28/30      8.49G      1.981      1.723       1.23          3        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.7it/s 49.0s0.3s\n                   all       2077       3638      0.391      0.408      0.381      0.177\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      29/30      8.59G      1.985      1.736      1.227         10        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.7it/s 48.9s0.3s\n                   all       2077       3638      0.388      0.415      0.386      0.179\n\n      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n\u001b[K      30/30      8.57G      1.969       1.69      1.226          2        640: 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 1021/1021 1.7it/s 10:04<0.3s\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.7it/s 48.9s0.3s\n                   all       2077       3638      0.379      0.427      0.388       0.18\n\n30 epochs completed in 5.487 hours.\nOptimizer stripped from /kaggle/working/runs/detect/runs/yolo11x/vindr_spinexr/weights/last.pt, 114.4MB\nOptimizer stripped from /kaggle/working/runs/detect/runs/yolo11x/vindr_spinexr/weights/best.pt, 114.4MB\n\nValidating /kaggle/working/runs/detect/runs/yolo11x/vindr_spinexr/weights/best.pt...\nUltralytics 8.4.7 üöÄ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\nYOLO11x summary (fused): 191 layers, 56,835,109 parameters, 0 gradients, 194.4 GFLOPs\n\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 130/130 2.6it/s 50.3s0.3s\n                   all       2077       3638      0.381      0.429       0.39      0.181\n           Osteophytes        878       2961      0.342      0.562      0.398      0.143\n      Surgical implant         64        107      0.605       0.72      0.705      0.429\n     Spondylolysthesis         62         69      0.313      0.464      0.406       0.16\n    Foraminal stenosis         60         94      0.623      0.334      0.441      0.152\n  Disc space narrowing        148        230        0.3      0.317      0.265      0.129\n    Vertebral collapse         52         69      0.445      0.594      0.497      0.247\n         Other lesions         80        108     0.0389    0.00926     0.0204     0.0084\nSpeed: 0.2ms preprocess, 18.3ms inference, 0.0ms loss, 1.2ms postprocess per image\nResults saved to \u001b[1m/kaggle/working/runs/detect/runs/yolo11x/vindr_spinexr\u001b[0m\n\n================================================================================\nTRAINING COMPLETED!\n================================================================================\n","output_type":"stream"}],"execution_count":13},{"id":"8bc60c4f","cell_type":"code","source":"# Emergency Backup - Save checkpoint info\nimport json\nfrom datetime import datetime\n\nbackup_info = {\n    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n    'status': 'completed',\n    'checkpoint_location': 'runs/yolo11x/vindr_spinexr/weights/best.pt',\n    'last_checkpoint': 'runs/yolo11x/vindr_spinexr/weights/last.pt',\n    'total_epochs': EPOCHS,\n    'message': 'Training completed successfully! Model saved.'\n}\n\n# Save backup info\nwith open('/kaggle/working/training_status.json', 'w') as f:\n    json.dump(backup_info, f, indent=2)\n\nprint(\"\\nüíæ Emergency backup info saved to: /kaggle/working/training_status.json\")\nprint(\"‚úì All checkpoints preserved in: runs/yolo11x/vindr_spinexr/\")\nprint(\"\\nüìä If session expires before downloading:\")\nprint(\"   1. Re-open this notebook\")\nprint(\"   2. Checkpoints are automatically saved in /kaggle/working/\")\nprint(\"   3. Run the 'Export Model' cells below to retrieve results\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.352047Z","iopub.execute_input":"2026-01-23T17:44:24.352523Z","iopub.status.idle":"2026-01-23T17:44:24.364304Z","shell.execute_reply.started":"2026-01-23T17:44:24.352483Z","shell.execute_reply":"2026-01-23T17:44:24.363553Z"}},"outputs":[{"name":"stdout","text":"\nüíæ Emergency backup info saved to: /kaggle/working/training_status.json\n‚úì All checkpoints preserved in: runs/yolo11x/vindr_spinexr/\n\nüìä If session expires before downloading:\n   1. Re-open this notebook\n   2. Checkpoints are automatically saved in /kaggle/working/\n   3. Run the 'Export Model' cells below to retrieve results\n","output_type":"stream"}],"execution_count":14},{"id":"5610596e","cell_type":"markdown","source":"## Step 8: Evaluate Results","metadata":{}},{"id":"e7a0d4df","cell_type":"code","source":"# Display training results\nprint(\"\\nFinal Training Metrics:\")\nprint(\"=\"*80)\n\nif hasattr(results, 'results_dict'):\n    metrics = results.results_dict\n    \n    if 'metrics/mAP50(B)' in metrics:\n        map50 = metrics['metrics/mAP50(B)']\n        print(f\"\\nmAP@0.5: {map50:.4f} ({map50*100:.2f}%)\")\n        \n        # Compare to baselines\n        print(f\"\\nComparison:\")\n        print(f\"  YOLO11-l expected: 32-36%\")\n        print(f\"  YOLO11-x (this): {map50*100:.2f}%\")\n        \n        if map50 >= 0.35:\n            improvement = (map50*100) - 34  # vs YOLO11-l average\n            print(f\"  ‚úÖ Improvement: +{improvement:.1f}%\")\n        else:\n            print(f\"  ‚ö†Ô∏è  Below expected range\")\n    \n    if 'metrics/mAP50-95(B)' in metrics:\n        map5095 = metrics['metrics/mAP50-95(B)']\n        print(f\"\\nmAP@0.5:0.95: {map5095:.4f} ({map5095*100:.2f}%)\")\n    \n    # Per-class metrics (if available)\n    print(\"\\nPer-Class Performance:\")\n    class_names = ['Osteophytes', 'Surgical implant', 'Spondylolysthesis', \n                   'Foraminal stenosis', 'Disc space narrowing', \n                   'Vertebral collapse', 'Other lesions']\n    \n    for i, name in enumerate(class_names):\n        key = f'metrics/mAP50({i})'\n        if key in metrics:\n            class_map = metrics[key] * 100\n            print(f\"  {name:<25}: {class_map:>6.2f}%\")\n\nprint(\"\\n\" + \"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.365919Z","iopub.execute_input":"2026-01-23T17:44:24.366178Z","iopub.status.idle":"2026-01-23T17:44:24.415255Z","shell.execute_reply.started":"2026-01-23T17:44:24.366154Z","shell.execute_reply":"2026-01-23T17:44:24.414541Z"}},"outputs":[{"name":"stdout","text":"\nFinal Training Metrics:\n================================================================================\n\nmAP@0.5: 0.3903 (39.03%)\n\nComparison:\n  YOLO11-l expected: 32-36%\n  YOLO11-x (this): 39.03%\n  ‚úÖ Improvement: +5.0%\n\nmAP@0.5:0.95: 0.1812 (18.12%)\n\nPer-Class Performance:\n\n================================================================================\n","output_type":"stream"}],"execution_count":15},{"id":"e0af14a1","cell_type":"code","source":"# Display training curves\nfrom IPython.display import Image, display\nimport os\n\nresults_dir = 'runs/yolo11x/vindr_spinexr'\n\nprint(\"Training Results Visualization:\\n\")\n\n# Results plot\nresults_img = f'{results_dir}/results.png'\nif os.path.exists(results_img):\n    print(\"Training Curves (Loss, mAP, Precision, Recall):\")\n    display(Image(filename=results_img, width=1000))\nelse:\n    print(\"Results plot not found\")\n\n# Confusion matrix\nconfusion_img = f'{results_dir}/confusion_matrix.png'\nif os.path.exists(confusion_img):\n    print(\"\\nConfusion Matrix:\")\n    display(Image(filename=confusion_img, width=800))\n\n# Sample predictions\nval_batch_img = f'{results_dir}/val_batch0_pred.jpg'\nif os.path.exists(val_batch_img):\n    print(\"\\nSample Predictions on Validation Set:\")\n    display(Image(filename=val_batch_img, width=1000))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.416252Z","iopub.execute_input":"2026-01-23T17:44:24.416887Z","iopub.status.idle":"2026-01-23T17:44:24.439250Z","shell.execute_reply.started":"2026-01-23T17:44:24.416847Z","shell.execute_reply":"2026-01-23T17:44:24.438721Z"}},"outputs":[{"name":"stdout","text":"Training Results Visualization:\n\nResults plot not found\n","output_type":"stream"}],"execution_count":16},{"id":"c89d3745","cell_type":"markdown","source":"## Step 9: Validate Best Model","metadata":{}},{"id":"89872b7a","cell_type":"code","source":"# Load best model and validate\nprint(\"Validating best model...\\n\")\n\nbest_model = YOLO(f'{results_dir}/weights/best.pt')\n\n# Validate without TTA\nval_results = best_model.val(\n    data=yaml_path,\n    split='val',\n    batch=16,  # Larger batch for validation (no gradients)\n    imgsz=640,\n    device=DEVICE,\n    plots=True,\n    save_json=True,\n    verbose=True\n)\n\nprint(\"\\n‚úì Validation complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.440304Z","iopub.execute_input":"2026-01-23T17:44:24.440685Z","iopub.status.idle":"2026-01-23T17:44:24.793952Z","shell.execute_reply.started":"2026-01-23T17:44:24.440645Z","shell.execute_reply":"2026-01-23T17:44:24.792417Z"}},"outputs":[{"name":"stdout","text":"Validating best model...\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/681515977.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validating best model...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{results_dir}/weights/best.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Validate without TTA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/models/yolo/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;31m# Continue with default YOLO initialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"RTDETR\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# if RTDETR head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRTDETR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, task, verbose)\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;31m# Delete super().training for accessing self.model.training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(self, weights, task)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset_ckpt_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mload_checkpoint\u001b[0;34m(weight, device, inplace, fuse)\u001b[0m\n\u001b[1;32m   1487\u001b[0m         \u001b[0mckpt\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mModel\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \"\"\"\n\u001b[0;32m-> 1489\u001b[0;31m     \u001b[0mckpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_safe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load ckpt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1490\u001b[0m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mDEFAULT_CFG_DICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_args\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m  \u001b[0;31m# combine model and default args, preferring model args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1491\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mckpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ema\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mckpt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# FP32 model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/nn/tasks.py\u001b[0m in \u001b[0;36mtorch_safe_load\u001b[0;34m(weight, safe_only)\u001b[0m\n\u001b[1;32m   1435\u001b[0m                     \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msafe_pickle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1437\u001b[0;31m                 \u001b[0mckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mModuleNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# e.name is missing module name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ultralytics/utils/patches.py\u001b[0m in \u001b[0;36mtorch_load\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weights_only\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1482\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFileLike\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"w\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mIO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'runs/yolo11x/vindr_spinexr/weights/best.pt'"],"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'runs/yolo11x/vindr_spinexr/weights/best.pt'","output_type":"error"}],"execution_count":17},{"id":"6f146544","cell_type":"markdown","source":"## Step 10: Test-Time Augmentation (TTA) - Optional Boost","metadata":{}},{"id":"62fe8e60","cell_type":"code","source":"# TTA can provide +1-2% mAP boost\nprint(\"Running Test-Time Augmentation (TTA)...\")\nprint(\"This will take 3-4x longer but may improve accuracy by 1-2%\\n\")\n\ntta_results = best_model.val(\n    data=yaml_path,\n    split='val',\n    batch=8,  # Smaller batch for TTA (more memory needed)\n    imgsz=640,\n    device=DEVICE,\n    augment=True,  # Enable TTA\n    verbose=True\n)\n\nprint(\"\\n‚úì TTA validation complete\")\nprint(f\"\\nTTA mAP@0.5: {tta_results.box.map50:.4f} ({tta_results.box.map50*100:.2f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.794828Z","iopub.status.idle":"2026-01-23T17:44:24.795204Z","shell.execute_reply.started":"2026-01-23T17:44:24.795067Z","shell.execute_reply":"2026-01-23T17:44:24.795087Z"}},"outputs":[],"execution_count":null},{"id":"d5215860","cell_type":"markdown","source":"## Step 11: Export Model & Save Results","metadata":{}},{"id":"57e3b83e","cell_type":"code","source":"# Export model weights\nprint(\"Saving model and results...\\n\")\n\n# Copy best weights to output\nimport shutil\n\noutput_dir = '/kaggle/working/yolo11x_output'\nos.makedirs(output_dir, exist_ok=True)\n\n# Copy weights\nshutil.copy2(f'{results_dir}/weights/best.pt', f'{output_dir}/yolo11x_best.pt')\nshutil.copy2(f'{results_dir}/weights/last.pt', f'{output_dir}/yolo11x_last.pt')\n\n# Copy training results\nif os.path.exists(f'{results_dir}/results.csv'):\n    shutil.copy2(f'{results_dir}/results.csv', f'{output_dir}/training_results.csv')\n\nif os.path.exists(f'{results_dir}/results.png'):\n    shutil.copy2(f'{results_dir}/results.png', f'{output_dir}/training_curves.png')\n\nif os.path.exists(f'{results_dir}/confusion_matrix.png'):\n    shutil.copy2(f'{results_dir}/confusion_matrix.png', f'{output_dir}/confusion_matrix.png')\n\nprint(f\"‚úì Model and results saved to: {output_dir}\")\nprint(f\"\\nFiles:\")\nfor file in os.listdir(output_dir):\n    size = os.path.getsize(f'{output_dir}/{file}') / 1024**2\n    print(f\"  - {file} ({size:.1f} MB)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.796735Z","iopub.status.idle":"2026-01-23T17:44:24.797112Z","shell.execute_reply.started":"2026-01-23T17:44:24.796904Z","shell.execute_reply":"2026-01-23T17:44:24.796939Z"}},"outputs":[],"execution_count":null},{"id":"eb1ff978","cell_type":"markdown","source":"## Step 12: Generate Summary Report","metadata":{}},{"id":"45e7068d","cell_type":"code","source":"import json\nfrom datetime import datetime\n\n# Create summary report\nsummary = {\n    'model': 'YOLO11-x',\n    'parameters': '65M',\n    'dataset': 'VinDr-SpineXR',\n    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n    'training_images': train_count,\n    'validation_images': val_count,\n    'epochs': EPOCHS,\n    'batch_size': BATCH_SIZE,\n    'image_size': IMG_SIZE,\n    'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n}\n\n# Add metrics\nif hasattr(results, 'results_dict'):\n    metrics = results.results_dict\n    if 'metrics/mAP50(B)' in metrics:\n        summary['map50'] = float(metrics['metrics/mAP50(B)'])\n    if 'metrics/mAP50-95(B)' in metrics:\n        summary['map50_95'] = float(metrics['metrics/mAP50-95(B)'])\n\n# Save summary\nwith open(f'{output_dir}/training_summary.json', 'w') as f:\n    json.dump(summary, f, indent=2)\n\nprint(\"=\"*80)\nprint(\"TRAINING SUMMARY\")\nprint(\"=\"*80)\nprint(json.dumps(summary, indent=2))\nprint(\"\\n\" + \"=\"*80)\nprint(\"‚úì Training completed successfully!\")\nprint(f\"‚úì Results saved to: {output_dir}\")\nprint(\"\\nTo download results:\")\nprint(\"  1. Click 'Output' tab in right sidebar\")\nprint(\"  2. Download 'yolo11x_output' folder\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.798411Z","iopub.status.idle":"2026-01-23T17:44:24.798758Z","shell.execute_reply.started":"2026-01-23T17:44:24.798558Z","shell.execute_reply":"2026-01-23T17:44:24.798588Z"}},"outputs":[],"execution_count":null},{"id":"31b21834","cell_type":"markdown","source":"## Step 13: Make Predictions (Optional)","metadata":{}},{"id":"f7cb22cf","cell_type":"code","source":"# Example: Make predictions on validation images\nfrom IPython.display import Image as IPImage, display\n\n# Get sample validation images\nval_images_dir = f'{DATASET_DIR}/images/val'\nsample_images = [os.path.join(val_images_dir, f) for f in os.listdir(val_images_dir)[:5]]\n\nprint(\"Sample Predictions:\")\nprint(\"=\"*80)\n\nfor img_path in sample_images:\n    # Predict\n    results = best_model.predict(\n        source=img_path,\n        conf=0.25,  # Confidence threshold\n        iou=0.7,    # NMS IoU threshold\n        device=DEVICE,\n        save=True,\n        project=f'{output_dir}/predictions',\n        name='samples',\n        exist_ok=True\n    )\n    \n    print(f\"\\nImage: {os.path.basename(img_path)}\")\n    print(f\"Detections: {len(results[0].boxes)} lesions found\")\n    \n    # Display detected classes\n    if len(results[0].boxes) > 0:\n        for box in results[0].boxes:\n            cls_id = int(box.cls[0])\n            conf = float(box.conf[0])\n            cls_name = class_names[cls_id]\n            print(f\"  - {cls_name}: {conf:.2%}\")\n    else:\n        print(\"  - No lesions detected\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(f\"Predictions saved to: {output_dir}/predictions/samples/\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T17:44:24.799852Z","iopub.status.idle":"2026-01-23T17:44:24.800186Z","shell.execute_reply.started":"2026-01-23T17:44:24.800016Z","shell.execute_reply":"2026-01-23T17:44:24.800044Z"}},"outputs":[],"execution_count":null},{"id":"f41a08f0","cell_type":"markdown","source":"## Next Steps\n\n1. **Download Results**: Click 'Output' tab ‚Üí Download 'yolo11x_output' folder\n2. **Compare with YOLO11-l**: Expected improvement: +3-5% mAP@0.5\n3. **Ensemble**: Combine YOLO11-x with other models for best results\n4. **Deploy**: Use best.pt for inference on new spine X-rays\n\n### Model Files:\n- `yolo11x_best.pt` - Best checkpoint (highest mAP@0.5)\n- `yolo11x_last.pt` - Last epoch checkpoint\n- `training_summary.json` - Complete training metrics\n- `training_curves.png` - Loss and accuracy curves\n- `confusion_matrix.png` - Per-class performance\n\n### Expected Performance:\n```\nYOLO11-l:  32-36% mAP@0.5\nYOLO11-x:  35-39% mAP@0.5  (+3-5% improvement)\n```\n\n### Questions?\nCheck the confusion matrix and per-class metrics to identify which lesion types need improvement.\nConsider ensemble with classification models (DenseNet, EfficientNet) for further boost!","metadata":{}}]}