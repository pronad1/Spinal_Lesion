{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4e317d",
   "metadata": {},
   "source": [
    "# YOLO11-x Training on VinDr-SpineXR Dataset\n",
    "## Kaggle GPU Optimized (Tesla P100/T4 16GB)\n",
    "\n",
    "**Model**: YOLO11-x (65M parameters)\n",
    "\n",
    "**Expected Performance**: 35-39% mAP@0.5 (vs 32-36% with YOLO11-l)\n",
    "\n",
    "**Training Time**: ~10-12 hours on Kaggle GPU\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ecb2cc",
   "metadata": {},
   "source": [
    "## Step 1: Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e670d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected! Training will be extremely slow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef45f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install/Upgrade Ultralytics (YOLO11)\n",
    "!pip install -U ultralytics\n",
    "!pip install -U opencv-python-headless\n",
    "\n",
    "# Verify installation\n",
    "from ultralytics import YOLO\n",
    "print(\"‚úì Ultralytics installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb584c",
   "metadata": {},
   "source": [
    "## Step 2: Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbec1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Kaggle dataset paths\n",
    "KAGGLE_INPUT = '/kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset'\n",
    "\n",
    "# Check if dataset exists\n",
    "if os.path.exists(KAGGLE_INPUT):\n",
    "    print(\"‚úì Dataset found!\")\n",
    "    print(\"\\nDataset structure:\")\n",
    "    for root, dirs, files in os.walk(KAGGLE_INPUT):\n",
    "        level = root.replace(KAGGLE_INPUT, '').count(os.sep)\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files[:3]:  # Show first 3 files only\n",
    "            print(f'{subindent}{file}')\n",
    "        if len(files) > 3:\n",
    "            print(f'{subindent}... and {len(files)-3} more files')\n",
    "        if level > 2:  # Limit depth\n",
    "            break\n",
    "else:\n",
    "    print(\"‚ùå Dataset not found!\")\n",
    "    print(\"Please add the dataset: https://www.kaggle.com/datasets/prosenjitmondol/complete-vindr-spinexr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014e651c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YOLO format dataset structure\n",
    "WORK_DIR = '/kaggle/working'\n",
    "DATASET_DIR = f'{WORK_DIR}/vindr_yolo'\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(f'{DATASET_DIR}/images/train', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_DIR}/images/val', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_DIR}/labels/train', exist_ok=True)\n",
    "os.makedirs(f'{DATASET_DIR}/labels/val', exist_ok=True)\n",
    "\n",
    "print(\"‚úì Directory structure created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d749f620",
   "metadata": {},
   "source": [
    "## Step 3: Convert COCO to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8708e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_to_yolo(coco_json_path, images_dir, output_labels_dir, output_images_dir):\n",
    "    \"\"\"\n",
    "    Convert COCO format annotations to YOLO format\n",
    "    \"\"\"\n",
    "    print(f\"Converting {coco_json_path}...\")\n",
    "    \n",
    "    with open(coco_json_path, 'r') as f:\n",
    "        coco_data = json.load(f)\n",
    "    \n",
    "    # Build image info dict\n",
    "    images_info = {img['id']: img for img in coco_data['images']}\n",
    "    \n",
    "    # Build category mapping (COCO uses 1-indexed, YOLO uses 0-indexed)\n",
    "    category_mapping = {cat['id']: idx for idx, cat in enumerate(coco_data['categories'])}\n",
    "    \n",
    "    # Group annotations by image_id\n",
    "    annotations_by_image = {}\n",
    "    for ann in coco_data['annotations']:\n",
    "        img_id = ann['image_id']\n",
    "        if img_id not in annotations_by_image:\n",
    "            annotations_by_image[img_id] = []\n",
    "        annotations_by_image[img_id].append(ann)\n",
    "    \n",
    "    converted_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    for img_id, img_info in images_info.items():\n",
    "        file_name = img_info['file_name']\n",
    "        img_width = img_info['width']\n",
    "        img_height = img_info['height']\n",
    "        \n",
    "        # Check for PNG version (train_png/test_png)\n",
    "        img_name_base = os.path.splitext(file_name)[0]\n",
    "        src_image_path = os.path.join(images_dir, f'{img_name_base}.png')\n",
    "        \n",
    "        # Fallback to original if PNG doesn't exist\n",
    "        if not os.path.exists(src_image_path):\n",
    "            src_image_path = os.path.join(images_dir.replace('_png', '_images'), file_name)\n",
    "        \n",
    "        if not os.path.exists(src_image_path):\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        # Copy image\n",
    "        dst_image_path = os.path.join(output_images_dir, f'{img_name_base}.png')\n",
    "        if not os.path.exists(dst_image_path):\n",
    "            shutil.copy2(src_image_path, dst_image_path)\n",
    "        \n",
    "        # Convert annotations to YOLO format\n",
    "        yolo_annotations = []\n",
    "        if img_id in annotations_by_image:\n",
    "            for ann in annotations_by_image[img_id]:\n",
    "                category_id = category_mapping[ann['category_id']]\n",
    "                bbox = ann['bbox']  # [x, y, width, height] in COCO\n",
    "                \n",
    "                # Convert to YOLO format: [class, x_center, y_center, width, height] (normalized)\n",
    "                x_center = (bbox[0] + bbox[2] / 2) / img_width\n",
    "                y_center = (bbox[1] + bbox[3] / 2) / img_height\n",
    "                width = bbox[2] / img_width\n",
    "                height = bbox[3] / img_height\n",
    "                \n",
    "                yolo_annotations.append(f\"{category_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\")\n",
    "        \n",
    "        # Write YOLO label file\n",
    "        label_path = os.path.join(output_labels_dir, f'{img_name_base}.txt')\n",
    "        with open(label_path, 'w') as f:\n",
    "            f.write('\\n'.join(yolo_annotations))\n",
    "        \n",
    "        converted_count += 1\n",
    "        if converted_count % 1000 == 0:\n",
    "            print(f\"  Converted {converted_count} images...\")\n",
    "    \n",
    "    print(f\"‚úì Converted {converted_count} images\")\n",
    "    if skipped_count > 0:\n",
    "        print(f\"‚ö† Skipped {skipped_count} images (not found)\")\n",
    "    \n",
    "    return converted_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dbe089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training data\n",
    "# Based on actual Kaggle dataset structure from screenshot\n",
    "import glob\n",
    "\n",
    "# Correct paths from your Kaggle dataset structure\n",
    "train_json = '/kaggle/input/complete-vindr-spinexr/coco format/train_coco.json'\n",
    "train_images = '/kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset/vindr-spinexr-a-large-annotated-medical-image-dataset/train_png'\n",
    "\n",
    "print(\"Checking training dataset paths...\")\n",
    "print(f\"JSON: {train_json}\")\n",
    "print(f\"Images: {train_images}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if not os.path.exists(train_json):\n",
    "    print(f\"‚ùå ERROR: JSON not found at {train_json}\")\n",
    "    train_count = 0\n",
    "elif not os.path.exists(train_images):\n",
    "    print(f\"‚ùå ERROR: Images folder not found at {train_images}\")\n",
    "    train_count = 0\n",
    "else:\n",
    "    # Count images\n",
    "    sample_files = glob.glob(os.path.join(train_images, '*.png'))\n",
    "    print(f\"‚úì Found {len(sample_files)} PNG files\\n\")\n",
    "    \n",
    "    # Convert\n",
    "    train_count = coco_to_yolo(\n",
    "        train_json,\n",
    "        train_images,\n",
    "        f'{DATASET_DIR}/labels/train',\n",
    "        f'{DATASET_DIR}/images/train'\n",
    "    )\n",
    "    print(f\"\\n‚úì Total training images converted: {train_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a39e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert validation/test data\n",
    "# Based on actual Kaggle dataset structure\n",
    "val_json = '/kaggle/input/complete-vindr-spinexr/coco format/test_coco.json'\n",
    "val_images = '/kaggle/input/complete-vindr-spinexr/vindr-spinexr-a-large-annotated-medical-image-dataset/vindr-spinexr-a-large-annotated-medical-image-dataset/test_png'\n",
    "\n",
    "print(\"Checking validation dataset paths...\")\n",
    "print(f\"JSON: {val_json}\")\n",
    "print(f\"Images: {val_images}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if not os.path.exists(val_json):\n",
    "    print(f\"‚ùå ERROR: JSON not found at {val_json}\")\n",
    "    val_count = 0\n",
    "elif not os.path.exists(val_images):\n",
    "    print(f\"‚ùå ERROR: Images folder not found at {val_images}\")\n",
    "    val_count = 0\n",
    "else:\n",
    "    # Count images\n",
    "    sample_files = glob.glob(os.path.join(val_images, '*.png'))\n",
    "    print(f\"‚úì Found {len(sample_files)} PNG files\\n\")\n",
    "    \n",
    "    # Convert\n",
    "    val_count = coco_to_yolo(\n",
    "        val_json,\n",
    "        val_images,\n",
    "        f'{DATASET_DIR}/labels/val',\n",
    "        f'{DATASET_DIR}/images/val'\n",
    "    )\n",
    "    print(f\"\\n‚úì Total validation images converted: {val_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d567253",
   "metadata": {},
   "source": [
    "## Step 4: Create YAML Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f1b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset YAML file\n",
    "yaml_content = f\"\"\"# VinDr-SpineXR Dataset Configuration for YOLO11-x\n",
    "\n",
    "path: {DATASET_DIR}\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "# Number of classes\n",
    "nc: 7\n",
    "\n",
    "# Class names\n",
    "names:\n",
    "  0: Osteophytes\n",
    "  1: Surgical implant\n",
    "  2: Spondylolysthesis\n",
    "  3: Foraminal stenosis\n",
    "  4: Disc space narrowing\n",
    "  5: Vertebral collapse\n",
    "  6: Other lesions\n",
    "\"\"\"\n",
    "\n",
    "yaml_path = f'{WORK_DIR}/vindr_spinexr.yaml'\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"‚úì Dataset YAML created\")\n",
    "print(f\"\\nConfiguration saved to: {yaml_path}\")\n",
    "print(\"\\nContents:\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b438d",
   "metadata": {},
   "source": [
    "## Step 5: Load YOLO11-x Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bef6793",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LOADING YOLO11-x MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load YOLO11-x with COCO pretrained weights\n",
    "model = YOLO('yolo11x.pt')  # Auto-downloads ~140MB\n",
    "\n",
    "print(\"\\n‚úì YOLO11-x loaded successfully!\")\n",
    "print(f\"\\nModel Details:\")\n",
    "print(f\"  Parameters: ~65M\")\n",
    "print(f\"  Architecture: YOLO11-x\")\n",
    "print(f\"  Pretrained: COCO dataset\")\n",
    "print(f\"  Input size: 640√ó640\")\n",
    "print(f\"\\nExpected Performance:\")\n",
    "print(f\"  mAP@0.5: 35-39% (vs 32-36% with YOLO11-l)\")\n",
    "print(f\"  Training time: ~10-12 hours on Kaggle GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9227a34",
   "metadata": {},
   "source": [
    "## Step 6: Configure Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2cfedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration optimized for Kaggle GPU (16GB)\n",
    "EPOCHS = 30  # Reduced from 35 to fit within 12-hour limit safely\n",
    "BATCH_SIZE = 8  # YOLO11-x with 16GB GPU (vs batch=12 for YOLO11-l)\n",
    "IMG_SIZE = 640\n",
    "DEVICE = 0\n",
    "\n",
    "print(\"Training Configuration:\")\n",
    "print(f\"  Model: YOLO11-x (65M parameters)\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"  Image Size: {IMG_SIZE}√ó{IMG_SIZE}\")\n",
    "print(f\"  Device: GPU {DEVICE if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"\\nDataset Characteristics:\")\n",
    "print(f\"  Training images: {train_count}\")\n",
    "print(f\"  Validation images: {val_count}\")\n",
    "print(f\"  Classes: 7 lesion types\")\n",
    "print(f\"  Class imbalance: ~46.9:1 (Osteophytes vs Vertebral collapse)\")\n",
    "print(f\"\\nOptimizations:\")\n",
    "print(f\"  - Focal Loss (handles class imbalance)\")\n",
    "print(f\"  - Copy-paste augmentation (20%)\")\n",
    "print(f\"  - Multi-scale detection (P3-P5)\")\n",
    "print(f\"  - Mixed precision training (AMP)\")\n",
    "print(f\"  - Cosine learning rate schedule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2999e2",
   "metadata": {},
   "source": [
    "## Step 6.5: Check for Previous Training & Auto-Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868b8ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Check for existing training runs\n",
    "CHECKPOINT_DIR = 'runs/yolo11x/vindr_spinexr'\n",
    "RESUME_CHECKPOINT = None\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CHECKPOINT DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if os.path.exists(CHECKPOINT_DIR):\n",
    "    # Check for last.pt (most recent checkpoint)\n",
    "    last_checkpoint = os.path.join(CHECKPOINT_DIR, 'weights', 'last.pt')\n",
    "    \n",
    "    if os.path.exists(last_checkpoint):\n",
    "        print(f\"\\n‚úì Found previous training checkpoint!\")\n",
    "        print(f\"  Location: {last_checkpoint}\")\n",
    "        \n",
    "        # Try to read epoch info from results.csv\n",
    "        results_csv = os.path.join(CHECKPOINT_DIR, 'results.csv')\n",
    "        if os.path.exists(results_csv):\n",
    "            import pandas as pd\n",
    "            df = pd.read_csv(results_csv)\n",
    "            last_epoch = len(df)\n",
    "            print(f\"  Last completed epoch: {last_epoch}/{EPOCHS}\")\n",
    "            print(f\"  Remaining epochs: {EPOCHS - last_epoch}\")\n",
    "            \n",
    "            if last_epoch >= EPOCHS:\n",
    "                print(f\"\\n‚ö†Ô∏è  Training already completed!\")\n",
    "                print(f\"  To start fresh, delete: {CHECKPOINT_DIR}\")\n",
    "            else:\n",
    "                print(f\"\\n‚úÖ Will RESUME training from epoch {last_epoch + 1}\")\n",
    "                RESUME_CHECKPOINT = last_checkpoint\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Will RESUME training from last checkpoint\")\n",
    "            RESUME_CHECKPOINT = last_checkpoint\n",
    "    else:\n",
    "        print(\"\\nNo checkpoint found. Starting fresh training.\")\n",
    "else:\n",
    "    print(\"\\nNo previous training found. Starting fresh training.\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# Summary\n",
    "if RESUME_CHECKPOINT:\n",
    "    print(f\"\\nüîÑ RESUME MODE: Training will continue from last checkpoint\")\n",
    "    print(f\"   Checkpoint: {RESUME_CHECKPOINT}\")\n",
    "else:\n",
    "    print(f\"\\nüÜï FRESH START: Training will begin from epoch 1\")\n",
    "    print(f\"   Checkpoints will be saved every 5 epochs\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f2ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Setup auto-backup to prevent data loss\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "BACKUP_DIR = '/kaggle/working/backup_checkpoints'\n",
    "os.makedirs(BACKUP_DIR, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"BACKUP SYSTEM ACTIVATED\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n‚ö†Ô∏è  IMPORTANT: To save your training progress:\")\n",
    "print(\"   1. Training checkpoints auto-save to: runs/yolo11x/vindr_spinexr/weights/\")\n",
    "print(\"   2. After training completes or periodically:\")\n",
    "print(\"      - Go to 'Output' tab in Kaggle\")\n",
    "print(\"      - Click 'Save Version' to preserve files\")\n",
    "print(\"   3. Or download files manually during training\")\n",
    "print(\"\\nüí° TIP: Enable 'Version Settings' > 'Always Save Output' in notebook settings\")\n",
    "print(\"=\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21a14b8",
   "metadata": {},
   "source": [
    "## Step 7: Train YOLO11-x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2ec3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"STARTING TRAINING - YOLO11-x ON VinDr-SpineXR\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Determine if resuming or starting fresh\n",
    "if RESUME_CHECKPOINT:\n",
    "    print(f\"\\nüîÑ RESUMING from checkpoint: {RESUME_CHECKPOINT}\")\n",
    "    print(\"Previous training progress will continue...\")\n",
    "else:\n",
    "    print(\"\\nüÜï STARTING FRESH training\")\n",
    "    \n",
    "print(\"\\nEstimated time: 10-12 hours\")\n",
    "print(\"This cell will run continuously. Monitor progress below.\")\n",
    "print(\"\\nüíæ Auto-save: Checkpoints saved every 5 epochs\")\n",
    "print(\"‚ö†Ô∏è  Kaggle limit: 12-hour session (training will complete in time)\")\n",
    "print(\"üîÑ If interrupted: Re-run notebook to auto-resume\\n\")\n",
    "\n",
    "# Train the model (with resume support)\n",
    "results = model.train(\n",
    "    data=yaml_path,\n",
    "    epochs=EPOCHS,\n",
    "    batch=BATCH_SIZE,\n",
    "    imgsz=IMG_SIZE,\n",
    "    device=DEVICE,\n",
    "    resume=bool(RESUME_CHECKPOINT),  # Auto-resume if checkpoint exists\n",
    "    \n",
    "    # Optimizer settings\n",
    "    optimizer='AdamW',\n",
    "    lr0=0.0001,           # Initial learning rate\n",
    "    lrf=0.01,             # Final LR = lr0 * lrf\n",
    "    momentum=0.937,\n",
    "    weight_decay=0.0005,\n",
    "    warmup_epochs=3,\n",
    "    warmup_momentum=0.8,\n",
    "    warmup_bias_lr=0.1,\n",
    "    \n",
    "    # Loss weights (optimized for small objects + class imbalance)\n",
    "    box=7.5,              # Box loss weight\n",
    "    cls=0.5,              # Classification loss (focal loss handles imbalance)\n",
    "    dfl=1.5,              # Distribution focal loss\n",
    "    \n",
    "    # Data augmentation (optimized for medical imaging)\n",
    "    hsv_h=0.015,          # Hue augmentation (conservative for medical)\n",
    "    hsv_s=0.7,            # Saturation\n",
    "    hsv_v=0.4,            # Brightness\n",
    "    degrees=5.0,          # Rotation ¬±5¬∞\n",
    "    translate=0.1,        # Translation\n",
    "    scale=0.5,            # Scale variation (0.5-1.5x)\n",
    "    shear=0.0,            # No shear (too slow)\n",
    "    perspective=0.0,      # No perspective (too slow)\n",
    "    flipud=0.5,           # Vertical flip (spine X-rays)\n",
    "    fliplr=0.5,           # Horizontal flip\n",
    "    \n",
    "    # Copy-paste for minority classes (CRITICAL)\n",
    "    copy_paste=0.2,       # 20% copy-paste augmentation\n",
    "    \n",
    "    # Mosaic augmentation\n",
    "    mosaic=1.0,           # Enable mosaic (multi-scale learning)\n",
    "    mixup=0.0,            # Disable mixup (too slow)\n",
    "    \n",
    "    # Multi-scale training\n",
    "    multi_scale=False,    # Disable for speed (mosaic provides similar benefit)\n",
    "    \n",
    "    # Training schedule\n",
    "    patience=20,          # Early stopping patience\n",
    "    save=True,\n",
    "    save_period=5,        # Save checkpoint every 5 epochs (was 10, now more frequent for safety)\n",
    "    cache=False,          # Don't cache (large dataset)\n",
    "    workers=8,            # Dataloader workers (Kaggle has good CPU)\n",
    "    \n",
    "    # Output settings\n",
    "    project='runs/yolo11x',\n",
    "    name='vindr_spinexr',\n",
    "    exist_ok=True,\n",
    "    pretrained=True,      # Use COCO pretrained weights\n",
    "    verbose=True,\n",
    "    seed=42,\n",
    "    deterministic=False,\n",
    "    single_cls=False,\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    cos_lr=True,          # Cosine LR decay\n",
    "    close_mosaic=5,       # Disable mosaic last 5 epochs\n",
    "    \n",
    "    # Mixed precision (faster + less memory)\n",
    "    amp=True,             # Automatic Mixed Precision\n",
    "    \n",
    "    # Validation\n",
    "    val=True,\n",
    "    plots=True,\n",
    "    \n",
    "    # Image handling\n",
    "    rect=False,           # Square images for multi-scale\n",
    "    \n",
    "    # Regularization\n",
    "    dropout=0.1,\n",
    "    label_smoothing=0.0,  # Disabled for medical (hard labels)\n",
    "    \n",
    "    # NMS settings\n",
    "    iou=0.7,\n",
    "    max_det=300,\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc60c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emergency Backup - Save checkpoint info\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "backup_info = {\n",
    "    'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'status': 'completed',\n",
    "    'checkpoint_location': 'runs/yolo11x/vindr_spinexr/weights/best.pt',\n",
    "    'last_checkpoint': 'runs/yolo11x/vindr_spinexr/weights/last.pt',\n",
    "    'total_epochs': EPOCHS,\n",
    "    'message': 'Training completed successfully! Model saved.'\n",
    "}\n",
    "\n",
    "# Save backup info\n",
    "with open('/kaggle/working/training_status.json', 'w') as f:\n",
    "    json.dump(backup_info, f, indent=2)\n",
    "\n",
    "print(\"\\nüíæ Emergency backup info saved to: /kaggle/working/training_status.json\")\n",
    "print(\"‚úì All checkpoints preserved in: runs/yolo11x/vindr_spinexr/\")\n",
    "print(\"\\nüìä If session expires before downloading:\")\n",
    "print(\"   1. Re-open this notebook\")\n",
    "print(\"   2. Checkpoints are automatically saved in /kaggle/working/\")\n",
    "print(\"   3. Run the 'Export Model' cells below to retrieve results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5610596e",
   "metadata": {},
   "source": [
    "## Step 8: Evaluate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a0d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "print(\"\\nFinal Training Metrics:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if hasattr(results, 'results_dict'):\n",
    "    metrics = results.results_dict\n",
    "    \n",
    "    if 'metrics/mAP50(B)' in metrics:\n",
    "        map50 = metrics['metrics/mAP50(B)']\n",
    "        print(f\"\\nmAP@0.5: {map50:.4f} ({map50*100:.2f}%)\")\n",
    "        \n",
    "        # Compare to baselines\n",
    "        print(f\"\\nComparison:\")\n",
    "        print(f\"  YOLO11-l expected: 32-36%\")\n",
    "        print(f\"  YOLO11-x (this): {map50*100:.2f}%\")\n",
    "        \n",
    "        if map50 >= 0.35:\n",
    "            improvement = (map50*100) - 34  # vs YOLO11-l average\n",
    "            print(f\"  ‚úÖ Improvement: +{improvement:.1f}%\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  Below expected range\")\n",
    "    \n",
    "    if 'metrics/mAP50-95(B)' in metrics:\n",
    "        map5095 = metrics['metrics/mAP50-95(B)']\n",
    "        print(f\"\\nmAP@0.5:0.95: {map5095:.4f} ({map5095*100:.2f}%)\")\n",
    "    \n",
    "    # Per-class metrics (if available)\n",
    "    print(\"\\nPer-Class Performance:\")\n",
    "    class_names = ['Osteophytes', 'Surgical implant', 'Spondylolysthesis', \n",
    "                   'Foraminal stenosis', 'Disc space narrowing', \n",
    "                   'Vertebral collapse', 'Other lesions']\n",
    "    \n",
    "    for i, name in enumerate(class_names):\n",
    "        key = f'metrics/mAP50({i})'\n",
    "        if key in metrics:\n",
    "            class_map = metrics[key] * 100\n",
    "            print(f\"  {name:<25}: {class_map:>6.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0af14a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training curves\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "results_dir = 'runs/yolo11x/vindr_spinexr'\n",
    "\n",
    "print(\"Training Results Visualization:\\n\")\n",
    "\n",
    "# Results plot\n",
    "results_img = f'{results_dir}/results.png'\n",
    "if os.path.exists(results_img):\n",
    "    print(\"Training Curves (Loss, mAP, Precision, Recall):\")\n",
    "    display(Image(filename=results_img, width=1000))\n",
    "else:\n",
    "    print(\"Results plot not found\")\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_img = f'{results_dir}/confusion_matrix.png'\n",
    "if os.path.exists(confusion_img):\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    display(Image(filename=confusion_img, width=800))\n",
    "\n",
    "# Sample predictions\n",
    "val_batch_img = f'{results_dir}/val_batch0_pred.jpg'\n",
    "if os.path.exists(val_batch_img):\n",
    "    print(\"\\nSample Predictions on Validation Set:\")\n",
    "    display(Image(filename=val_batch_img, width=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d3745",
   "metadata": {},
   "source": [
    "## Step 9: Validate Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89872b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model and validate\n",
    "print(\"Validating best model...\\n\")\n",
    "\n",
    "best_model = YOLO(f'{results_dir}/weights/best.pt')\n",
    "\n",
    "# Validate without TTA\n",
    "val_results = best_model.val(\n",
    "    data=yaml_path,\n",
    "    split='val',\n",
    "    batch=16,  # Larger batch for validation (no gradients)\n",
    "    imgsz=640,\n",
    "    device=DEVICE,\n",
    "    plots=True,\n",
    "    save_json=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Validation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f146544",
   "metadata": {},
   "source": [
    "## Step 10: Test-Time Augmentation (TTA) - Optional Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fe8e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA can provide +1-2% mAP boost\n",
    "print(\"Running Test-Time Augmentation (TTA)...\")\n",
    "print(\"This will take 3-4x longer but may improve accuracy by 1-2%\\n\")\n",
    "\n",
    "tta_results = best_model.val(\n",
    "    data=yaml_path,\n",
    "    split='val',\n",
    "    batch=8,  # Smaller batch for TTA (more memory needed)\n",
    "    imgsz=640,\n",
    "    device=DEVICE,\n",
    "    augment=True,  # Enable TTA\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì TTA validation complete\")\n",
    "print(f\"\\nTTA mAP@0.5: {tta_results.box.map50:.4f} ({tta_results.box.map50*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5215860",
   "metadata": {},
   "source": [
    "## Step 11: Export Model & Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e3b83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model weights\n",
    "print(\"Saving model and results...\\n\")\n",
    "\n",
    "# Copy best weights to output\n",
    "import shutil\n",
    "\n",
    "output_dir = '/kaggle/working/yolo11x_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Copy weights\n",
    "shutil.copy2(f'{results_dir}/weights/best.pt', f'{output_dir}/yolo11x_best.pt')\n",
    "shutil.copy2(f'{results_dir}/weights/last.pt', f'{output_dir}/yolo11x_last.pt')\n",
    "\n",
    "# Copy training results\n",
    "if os.path.exists(f'{results_dir}/results.csv'):\n",
    "    shutil.copy2(f'{results_dir}/results.csv', f'{output_dir}/training_results.csv')\n",
    "\n",
    "if os.path.exists(f'{results_dir}/results.png'):\n",
    "    shutil.copy2(f'{results_dir}/results.png', f'{output_dir}/training_curves.png')\n",
    "\n",
    "if os.path.exists(f'{results_dir}/confusion_matrix.png'):\n",
    "    shutil.copy2(f'{results_dir}/confusion_matrix.png', f'{output_dir}/confusion_matrix.png')\n",
    "\n",
    "print(f\"‚úì Model and results saved to: {output_dir}\")\n",
    "print(f\"\\nFiles:\")\n",
    "for file in os.listdir(output_dir):\n",
    "    size = os.path.getsize(f'{output_dir}/{file}') / 1024**2\n",
    "    print(f\"  - {file} ({size:.1f} MB)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ff978",
   "metadata": {},
   "source": [
    "## Step 12: Generate Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e7068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Create summary report\n",
    "summary = {\n",
    "    'model': 'YOLO11-x',\n",
    "    'parameters': '65M',\n",
    "    'dataset': 'VinDr-SpineXR',\n",
    "    'training_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'training_images': train_count,\n",
    "    'validation_images': val_count,\n",
    "    'epochs': EPOCHS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'image_size': IMG_SIZE,\n",
    "    'gpu': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',\n",
    "}\n",
    "\n",
    "# Add metrics\n",
    "if hasattr(results, 'results_dict'):\n",
    "    metrics = results.results_dict\n",
    "    if 'metrics/mAP50(B)' in metrics:\n",
    "        summary['map50'] = float(metrics['metrics/mAP50(B)'])\n",
    "    if 'metrics/mAP50-95(B)' in metrics:\n",
    "        summary['map50_95'] = float(metrics['metrics/mAP50-95(B)'])\n",
    "\n",
    "# Save summary\n",
    "with open(f'{output_dir}/training_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì Training completed successfully!\")\n",
    "print(f\"‚úì Results saved to: {output_dir}\")\n",
    "print(\"\\nTo download results:\")\n",
    "print(\"  1. Click 'Output' tab in right sidebar\")\n",
    "print(\"  2. Download 'yolo11x_output' folder\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b21834",
   "metadata": {},
   "source": [
    "## Step 13: Make Predictions (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb22cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make predictions on validation images\n",
    "from IPython.display import Image as IPImage, display\n",
    "\n",
    "# Get sample validation images\n",
    "val_images_dir = f'{DATASET_DIR}/images/val'\n",
    "sample_images = [os.path.join(val_images_dir, f) for f in os.listdir(val_images_dir)[:5]]\n",
    "\n",
    "print(\"Sample Predictions:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for img_path in sample_images:\n",
    "    # Predict\n",
    "    results = best_model.predict(\n",
    "        source=img_path,\n",
    "        conf=0.25,  # Confidence threshold\n",
    "        iou=0.7,    # NMS IoU threshold\n",
    "        device=DEVICE,\n",
    "        save=True,\n",
    "        project=f'{output_dir}/predictions',\n",
    "        name='samples',\n",
    "        exist_ok=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nImage: {os.path.basename(img_path)}\")\n",
    "    print(f\"Detections: {len(results[0].boxes)} lesions found\")\n",
    "    \n",
    "    # Display detected classes\n",
    "    if len(results[0].boxes) > 0:\n",
    "        for box in results[0].boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            conf = float(box.conf[0])\n",
    "            cls_name = class_names[cls_id]\n",
    "            print(f\"  - {cls_name}: {conf:.2%}\")\n",
    "    else:\n",
    "        print(\"  - No lesions detected\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Predictions saved to: {output_dir}/predictions/samples/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41a08f0",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Download Results**: Click 'Output' tab ‚Üí Download 'yolo11x_output' folder\n",
    "2. **Compare with YOLO11-l**: Expected improvement: +3-5% mAP@0.5\n",
    "3. **Ensemble**: Combine YOLO11-x with other models for best results\n",
    "4. **Deploy**: Use best.pt for inference on new spine X-rays\n",
    "\n",
    "### Model Files:\n",
    "- `yolo11x_best.pt` - Best checkpoint (highest mAP@0.5)\n",
    "- `yolo11x_last.pt` - Last epoch checkpoint\n",
    "- `training_summary.json` - Complete training metrics\n",
    "- `training_curves.png` - Loss and accuracy curves\n",
    "- `confusion_matrix.png` - Per-class performance\n",
    "\n",
    "### Expected Performance:\n",
    "```\n",
    "YOLO11-l:  32-36% mAP@0.5\n",
    "YOLO11-x:  35-39% mAP@0.5  (+3-5% improvement)\n",
    "```\n",
    "\n",
    "### Questions?\n",
    "Check the confusion matrix and per-class metrics to identify which lesion types need improvement.\n",
    "Consider ensemble with classification models (DenseNet, EfficientNet) for further boost!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
