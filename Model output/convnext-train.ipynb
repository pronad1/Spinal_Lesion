{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14063335,"sourceType":"datasetVersion","datasetId":8951332}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### ConvNeXt","metadata":{}},{"cell_type":"markdown","source":"### Load data","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport timm\nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n\n# --- CONFIGURATION (PRO SETTINGS) ---\nConfig = {\n    'model_name': 'convnext_tiny', \n    'img_size': 224,\n    'batch_size': 32,             \n    'epochs': 15,                 # Increased to allow learning rare classes\n    'learning_rate': 3e-4,        # Slightly higher start, will decay\n    'weight_decay': 1e-5,         # Prevents overfitting\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'seed': 42\n}\n\n# --- PATHS ---\nROOT_DIR = \"/kaggle/input/vindr-spinexr-modified/vindr-spinexr-a-large-annotated-medical-image-dataset\"\nTRAIN_CSV_PATH = os.path.join(ROOT_DIR, \"annotations/train.csv\")\nTEST_CSV_PATH = os.path.join(ROOT_DIR, \"annotations/test.csv\")\nTRAIN_IMG_DIR = os.path.join(ROOT_DIR, \"train_png\")\nTEST_IMG_DIR = os.path.join(ROOT_DIR, \"test_png\")\n\nprint(f\"Device: {Config['device']}\")\nprint(\"Configuration Loaded.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T20:27:46.651522Z","iopub.execute_input":"2025-12-08T20:27:46.651977Z","iopub.status.idle":"2025-12-08T20:27:51.990201Z","shell.execute_reply.started":"2025-12-08T20:27:46.651951Z","shell.execute_reply":"2025-12-08T20:27:51.989410Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Device: cuda\nConfiguration Loaded.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Load Model","metadata":{}},{"cell_type":"code","source":"# 1. Load Data\ndf = pd.read_csv(TRAIN_CSV_PATH)\nID_COL = 'image_id'\nLABEL_COL = 'lesion_type'\n\n# 2. Preprocessing\n# Drop duplicates (Force Single-Label Classification)\ndf = df.drop_duplicates(subset=[ID_COL]).reset_index(drop=True)\n\n# Encode Labels\nencoder = LabelEncoder()\ndf['label_encoded'] = encoder.fit_transform(df[LABEL_COL])\nConfig['num_classes'] = len(encoder.classes_)\n\n# --- CRITICAL: CALCULATE CLASS WEIGHTS ---\n# This fixes the imbalance problem\nclass_weights = compute_class_weight(\n    class_weight='balanced', \n    classes=np.unique(df['label_encoded']), \n    y=df['label_encoded']\n)\nweights_tensor = torch.tensor(class_weights, dtype=torch.float).to(Config['device'])\n\nprint(\"Computed Class Weights (Penalty for missing):\")\nfor cls, w in zip(encoder.classes_, class_weights):\n    print(f\"  {cls}: {w:.2f}x\")\n\n# 3. Dataset Class\nclass SpineDataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.df = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_id = row[ID_COL]\n        # Handle extension\n        img_name = f\"{img_id}.png\" if not str(img_id).endswith('.png') else img_id\n        img_path = os.path.join(self.root_dir, img_name)\n        \n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except:\n            image = Image.new('RGB', (Config['img_size'], Config['img_size']))\n            \n        label = torch.tensor(row['label_encoded'], dtype=torch.long)\n\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# 4. Transforms (Stronger Augmentation)\ntrain_transforms = transforms.Compose([\n    transforms.Resize((Config['img_size'], Config['img_size'])),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15), \n    transforms.ColorJitter(brightness=0.1, contrast=0.1), # New: Helps model generalize\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((Config['img_size'], Config['img_size'])),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# 5. Loaders\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=Config['seed'], stratify=df['label_encoded'])\n\ntrain_loader = DataLoader(SpineDataset(train_df, TRAIN_IMG_DIR, train_transforms), \n                          batch_size=Config['batch_size'], shuffle=True, num_workers=2)\n\nval_loader = DataLoader(SpineDataset(val_df, TRAIN_IMG_DIR, val_transforms), \n                        batch_size=Config['batch_size'], shuffle=False, num_workers=2)\n\nprint(f\"Training on {len(train_df)} images | Validating on {len(val_df)} images\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T20:27:51.991674Z","iopub.execute_input":"2025-12-08T20:27:51.991975Z","iopub.status.idle":"2025-12-08T20:27:52.178918Z","shell.execute_reply.started":"2025-12-08T20:27:51.991947Z","shell.execute_reply":"2025-12-08T20:27:52.178056Z"}},"outputs":[{"name":"stdout","text":"Computed Class Weights (Penalty for missing):\n  Disc space narrowing: 4.77x\n  Foraminal stenosis: 4.50x\n  No finding: 0.25x\n  Osteophytes: 0.32x\n  Other lesions: 6.36x\n  Spondylolysthesis: 15.20x\n  Surgical implant: 7.77x\n  Vertebral collapse: 18.73x\nTraining on 6711 images | Validating on 1678 images\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Train model","metadata":{}},{"cell_type":"code","source":"# 1. Model Setup\nmodel = timm.create_model(Config['model_name'], pretrained=True)\nmodel.head.fc = nn.Linear(model.head.fc.in_features, Config['num_classes'])\nmodel = model.to(Config['device'])\n\n# 2. Loss & Optimizer (WITH WEIGHTS)\n# The 'weight' argument here tells the model: \"Pay attention to the rare classes!\"\ncriterion = nn.CrossEntropyLoss(weight=weights_tensor) \n\noptimizer = optim.AdamW(model.parameters(), lr=Config['learning_rate'], weight_decay=Config['weight_decay'])\n\n# Scheduler: Lowers LR if validation loss stops improving\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3, verbose=True)\n\n# 3. Training Loop\nbest_acc = 0.0\n\nprint(\"Starting Training...\")\n\nfor epoch in range(Config['epochs']):\n    # --- TRAIN ---\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    \n    # Using simple loop to avoid tqdm nesting issues\n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config['epochs']}\"):\n        images, labels = images.to(Config['device']), labels.to(Config['device'])\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels) # This loss is now WEIGHTED\n        loss.backward()\n        optimizer.step()\n        \n        train_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n    \n    avg_train_loss = train_loss / len(train_loader)\n    train_acc = 100 * correct / total\n    \n    # --- VALIDATE ---\n    model.eval()\n    val_loss = 0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(Config['device']), labels.to(Config['device'])\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n    avg_val_loss = val_loss / len(val_loader)\n    val_acc = 100 * correct / total\n    \n    # --- LOGGING ---\n    print(f\"Train Loss: {avg_train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n    print(f\"Val Loss:   {avg_val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n    \n    # Update Scheduler\n    scheduler.step(avg_val_loss)\n    \n    # Save Best\n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), \"best_convnext_model.pth\")\n        print(\">>> Best Model Saved!\")\n    print(\"-\" * 30)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T20:27:52.179691Z","iopub.execute_input":"2025-12-08T20:27:52.180005Z","iopub.status.idle":"2025-12-08T21:39:17.938860Z","shell.execute_reply.started":"2025-12-08T20:27:52.179983Z","shell.execute_reply":"2025-12-08T21:39:17.937959Z"}},"outputs":[{"name":"stdout","text":"Starting Training...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a2d4cf4607c848578f09ae0b0cb9a4e1"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.1864 | Train Acc: 11.24%\nVal Loss:   2.1389 | Val Acc:   1.61%\n>>> Best Model Saved!\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b8c687647b94e41b7071cdf66933e62"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.1166 | Train Acc: 19.52%\nVal Loss:   2.1050 | Val Acc:   38.74%\n>>> Best Model Saved!\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13d658e04f6d4f34befb0dea88489bc4"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.1018 | Train Acc: 20.95%\nVal Loss:   2.0735 | Val Acc:   50.77%\n>>> Best Model Saved!\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12f0940b4ddb433bb77418242c637a1e"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0941 | Train Acc: 27.78%\nVal Loss:   2.1073 | Val Acc:   1.97%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9e10494f4284f7687494785b5b5495a"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0953 | Train Acc: 18.61%\nVal Loss:   2.0658 | Val Acc:   50.77%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da5a1f8ef8bc45a09b621cab00cc883a"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0833 | Train Acc: 29.49%\nVal Loss:   2.0701 | Val Acc:   2.80%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c15c4b53e55a4fe2a606c1a88deb533c"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0801 | Train Acc: 33.56%\nVal Loss:   2.0622 | Val Acc:   2.62%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26dc3ad481914c71bddb8f57e4055fbb"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0791 | Train Acc: 35.14%\nVal Loss:   2.0576 | Val Acc:   50.77%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab13d15a514b4ae1a1ccb51a25a2f6e8"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0811 | Train Acc: 31.59%\nVal Loss:   2.0594 | Val Acc:   38.74%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd57ac82f8f34fa89e8af46d530e1c4f"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0999 | Train Acc: 31.99%\nVal Loss:   2.0562 | Val Acc:   38.74%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3be62ac1a56f43d7a017ef09c9815c68"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0840 | Train Acc: 34.67%\nVal Loss:   2.0663 | Val Acc:   50.42%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ee6a3a94a6f4f578434ffece5a506eb"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0707 | Train Acc: 33.29%\nVal Loss:   2.0731 | Val Acc:   2.62%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"740098aa75c443fbb8822ebcf70aa878"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 2.0603 | Train Acc: 36.88%\nVal Loss:   1.9921 | Val Acc:   40.46%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0782c1182424414e94741fe8552771da"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 1.9624 | Train Acc: 34.57%\nVal Loss:   1.8759 | Val Acc:   31.29%\n------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15/15:   0%|          | 0/210 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6c3a91ebc0f47d8a6e0bebfe12edb4f"}},"metadata":{}},{"name":"stdout","text":"Train Loss: 1.9029 | Train Acc: 26.73%\nVal Loss:   1.8618 | Val Acc:   21.22%\n------------------------------\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Test Model","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\nfrom sklearn.preprocessing import label_binarize\n\n# 1. Setup Test Data\ntest_df = pd.read_csv(TEST_CSV_PATH).drop_duplicates(subset=[ID_COL]).reset_index(drop=True)\n# Keep only classes we know\ntest_df = test_df[test_df[LABEL_COL].isin(encoder.classes_)]\ntest_df['label_encoded'] = encoder.transform(test_df[LABEL_COL])\n\ntest_dataset = SpineDataset(test_df, TEST_IMG_DIR, transform=val_transforms)\n# num_workers=0 to prevent freezing\ntest_loader = DataLoader(test_dataset, batch_size=Config['batch_size'], shuffle=False, num_workers=0)\n\n# 2. Load Best Model\nmodel.load_state_dict(torch.load(\"best_convnext_model.pth\"))\nmodel.eval()\n\n# 3. Predict\ny_true, y_pred, y_probs = [], [], []\n\nprint(\"Running Inference...\")\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader):\n        images = images.to(Config['device'])\n        outputs = model(images)\n        probs = torch.softmax(outputs, dim=1)\n        _, preds = torch.max(outputs, 1)\n        \n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n        y_probs.extend(probs.cpu().numpy())\n\n# 4. Metrics\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\ny_probs = np.array(y_probs)\n\nf1 = f1_score(y_true, y_pred, average='weighted')\n\n# Specificity & Sensitivity\ncm = confusion_matrix(y_true, y_pred)\nspecificities = []\nsensitivities = []\nfor i in range(Config['num_classes']):\n    tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n    fp = cm[:, i].sum() - cm[i, i]\n    fn = cm[i, :].sum() - cm[i, i]\n    tp = cm[i, i]\n    spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n    sens = tp / (tp + fn) if (tp + fn) > 0 else 0\n    specificities.append(spec)\n    sensitivities.append(sens)\n\navg_spec = np.mean(specificities)\navg_sens = np.mean(sensitivities)\n\n# AUROC\ntry:\n    if Config['num_classes'] == 2:\n        auroc = roc_auc_score(y_true, y_probs[:, 1])\n    else:\n        y_true_bin = label_binarize(y_true, classes=range(Config['num_classes']))\n        auroc = roc_auc_score(y_true_bin, y_probs, multi_class='ovr', average='weighted')\nexcept:\n    auroc = 0.5\n\nprint(\"\\n\" + \"=\"*40)\nprint(f\"{'METRIC':<15} | {'VALUE':<10}\")\nprint(\"-\" * 40)\nprint(f\"{'AUROC':<15} | {auroc*100:.2f}%\")\nprint(f\"{'F1 Score':<15} | {f1*100:.2f}%\")\nprint(f\"{'Sensitivity':<15} | {avg_sens*100:.2f}%\")\nprint(f\"{'Specificity':<15} | {avg_spec*100:.2f}%\")\nprint(\"=\"*40)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-08T21:39:17.939939Z","iopub.execute_input":"2025-12-08T21:39:17.940264Z","iopub.status.idle":"2025-12-08T21:41:15.951710Z","shell.execute_reply.started":"2025-12-08T21:39:17.940178Z","shell.execute_reply":"2025-12-08T21:41:15.950834Z"}},"outputs":[{"name":"stdout","text":"Running Inference...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/65 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a5b6ed3a00b44e5a3dc82c678732eca"}},"metadata":{}},{"name":"stdout","text":"\n========================================\nMETRIC          | VALUE     \n----------------------------------------\nAUROC           | 60.14%\nF1 Score        | 35.03%\nSensitivity     | 12.50%\nSpecificity     | 87.50%\n========================================\n","output_type":"stream"}],"execution_count":4}]}