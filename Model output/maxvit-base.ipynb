{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14063335,"sourceType":"datasetVersion","datasetId":8951332}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Install Dependencies","metadata":{}},{"cell_type":"code","source":"!pip install timm --no-deps\nimport timm\nprint(\"Timm version:\", timm.__version__)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:23:21.054423Z","iopub.execute_input":"2025-12-09T11:23:21.054813Z","iopub.status.idle":"2025-12-09T11:23:26.451561Z","shell.execute_reply.started":"2025-12-09T11:23:21.054778Z","shell.execute_reply":"2025-12-09T11:23:26.450758Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.11/dist-packages (1.0.19)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Timm version: 1.0.19\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### Configuration & Imports","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import roc_auc_score, f1_score, confusion_matrix\nfrom sklearn.preprocessing import label_binarize\nfrom PIL import Image\nfrom tqdm.notebook import tqdm\nimport timm\nimport warnings\nimport gc\n\nwarnings.filterwarnings(\"ignore\")\n\n# --- OPTIMIZED CONFIGURATION (Fixes OOM) ---\nConfig = {\n    'model_name': 'maxvit_base_tf_512.in21k_ft_in1k',\n    'img_size': 512,\n    'batch_size': 4,              # Reduced to fit VRAM\n    'accum_iter': 4,              # Effective Batch Size = 16\n    'epochs': 15,\n    'learning_rate': 2e-5,\n    'weight_decay': 0.05,\n    'drop_path_rate': 0.2,\n    'num_workers': 2,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'seed': 42\n}\n\n# --- PATHS ---\nROOT_DIR = \"/kaggle/input/vindr-spinexr-modified/vindr-spinexr-a-large-annotated-medical-image-dataset\"\nTRAIN_CSV_PATH = os.path.join(ROOT_DIR, \"annotations/train.csv\")\nTEST_CSV_PATH = os.path.join(ROOT_DIR, \"annotations/test.csv\")\nTRAIN_IMG_DIR = os.path.join(ROOT_DIR, \"train_png\")\nTEST_IMG_DIR = os.path.join(ROOT_DIR, \"test_png\")\n\n# --- DATASET CLASS ---\nclass SpineDataset(Dataset):\n    def __init__(self, dataframe, root_dir, transform=None):\n        self.df = dataframe\n        self.root_dir = root_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_id = row['image_id']\n        img_name = f\"{img_id}.png\" if not str(img_id).endswith('.png') else img_id\n        img_path = os.path.join(self.root_dir, img_name)\n        \n        try:\n            image = Image.open(img_path).convert(\"RGB\")\n        except:\n            image = Image.new('RGB', (Config['img_size'], Config['img_size']))\n            \n        label = torch.tensor(row['label_encoded'], dtype=torch.long)\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# --- PREPROCESSING ---\ndf = pd.read_csv(TRAIN_CSV_PATH).drop_duplicates(subset=['image_id']).reset_index(drop=True)\nencoder = LabelEncoder()\ndf['label_encoded'] = encoder.fit_transform(df['lesion_type'])\nConfig['num_classes'] = len(encoder.classes_)\n\n# Class Weights\nclass_weights = compute_class_weight('balanced', classes=np.unique(df['label_encoded']), y=df['label_encoded'])\nweights_tensor = torch.tensor(class_weights, dtype=torch.float).to(Config['device'])\n\n# Transforms\ntrain_transforms = transforms.Compose([\n    transforms.Resize((Config['img_size'], Config['img_size'])),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transforms = transforms.Compose([\n    transforms.Resize((Config['img_size'], Config['img_size'])),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Loaders\ntrain_df, val_df = train_test_split(df, test_size=0.2, random_state=Config['seed'], stratify=df['label_encoded'])\ntrain_loader = DataLoader(SpineDataset(train_df, TRAIN_IMG_DIR, train_transforms), \n                          batch_size=Config['batch_size'], shuffle=True, num_workers=Config['num_workers'])\nval_loader = DataLoader(SpineDataset(val_df, TRAIN_IMG_DIR, val_transforms), \n                        batch_size=Config['batch_size'], shuffle=False, num_workers=Config['num_workers'])\n\nprint(f\"Setup Complete. Training on {len(train_df)} images.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:23:30.102949Z","iopub.execute_input":"2025-12-09T11:23:30.103600Z","iopub.status.idle":"2025-12-09T11:23:31.182013Z","shell.execute_reply.started":"2025-12-09T11:23:30.103571Z","shell.execute_reply":"2025-12-09T11:23:31.181162Z"}},"outputs":[{"name":"stdout","text":"Setup Complete. Training on 6711 images.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### Model Initialization","metadata":{}},{"cell_type":"code","source":"import gc\n\n# 1. Force Clear Memory\ntorch.cuda.empty_cache()\ngc.collect()\n\nprint(f\"Allocated Memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n\n# 2. Create Model\nmodel = timm.create_model(\n    Config['model_name'], \n    pretrained=True, \n    num_classes=Config['num_classes'],\n    drop_path_rate=Config['drop_path_rate']\n)\n\n# 3. Move to Device safely\ntry:\n    model = model.to(Config['device'])\n    print(\"Model successfully moved to GPU.\")\nexcept RuntimeError as e:\n    print(f\"ERROR: {e}\")\n    print(\"Tip: Restart your kernel (Run > Restart Session) to clear old memory.\")\n\n# 4. Optimizer & Loss\noptimizer = optim.AdamW(model.parameters(), lr=Config['learning_rate'], weight_decay=Config['weight_decay'])\ncriterion = nn.CrossEntropyLoss(weight=weights_tensor)\nscheduler = optim.lr_scheduler.OneCycleLR(\n    optimizer, max_lr=Config['learning_rate'], steps_per_epoch=len(train_loader)//Config['accum_iter'], epochs=Config['epochs']\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:23:39.943664Z","iopub.execute_input":"2025-12-09T11:23:39.944267Z","iopub.status.idle":"2025-12-09T11:23:42.906522Z","shell.execute_reply.started":"2025-12-09T11:23:39.944239Z","shell.execute_reply":"2025-12-09T11:23:42.905902Z"}},"outputs":[{"name":"stdout","text":"Allocated Memory: 0.00 GB\nModel successfully moved to GPU.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### Training Loop (With AMP & Accumulation)","metadata":{}},{"cell_type":"code","source":"from torch.cuda.amp import autocast, GradScaler\n\nscaler = GradScaler()\nbest_acc = 0.0\n\nprint(f\"Starting Training for {Config['epochs']} Epochs...\")\n\nfor epoch in range(Config['epochs']):\n    # --- TRAIN ---\n    model.train()\n    train_loss = 0\n    correct = 0\n    total = 0\n    \n    optimizer.zero_grad()\n    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{Config['epochs']} [Train]\")\n    \n    for i, (images, labels) in enumerate(loop):\n        images, labels = images.to(Config['device']), labels.to(Config['device'])\n        \n        # Mixed Precision\n        with autocast():\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss = loss / Config['accum_iter'] # Normalize\n        \n        scaler.scale(loss).backward()\n        \n        if (i + 1) % Config['accum_iter'] == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            scheduler.step()\n        \n        train_loss += loss.item() * Config['accum_iter']\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        loop.set_postfix(loss=loss.item() * Config['accum_iter'])\n    \n    avg_train_loss = train_loss / len(train_loader)\n    \n    # Cleanup before validation\n    del images, labels, outputs\n    torch.cuda.empty_cache()\n    gc.collect()\n    \n    # --- VALIDATE ---\n    model.eval()\n    val_correct = 0\n    val_total = 0\n    \n    with torch.no_grad():\n        for images, labels in val_loader:\n            images, labels = images.to(Config['device']), labels.to(Config['device'])\n            with autocast():\n                outputs = model(images)\n            _, predicted = torch.max(outputs.data, 1)\n            val_total += labels.size(0)\n            val_correct += (predicted == labels).sum().item()\n            \n    val_acc = 100 * val_correct / val_total\n    print(f\"Epoch {epoch+1}: Train Loss: {avg_train_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n    \n    if val_acc > best_acc:\n        best_acc = val_acc\n        torch.save(model.state_dict(), \"maxvit_best_model.pth\")\n        print(f\"--> Best Model Saved! ({val_acc:.2f}%)\")\n    print(\"-\" * 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T11:24:27.124029Z","iopub.execute_input":"2025-12-09T11:24:27.124641Z","iopub.status.idle":"2025-12-09T19:01:16.683877Z","shell.execute_reply.started":"2025-12-09T11:24:27.124614Z","shell.execute_reply":"2025-12-09T19:01:16.682680Z"}},"outputs":[{"name":"stdout","text":"Starting Training for 15 Epochs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"722b6b7078d24febacba7e18f43c55c9"}},"metadata":{}},{"name":"stdout","text":"Epoch 1: Train Loss: 1.9942 | Val Acc: 54.77%\n--> Best Model Saved! (54.77%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"880f6bb562c34916a34592aecc460e8a"}},"metadata":{}},{"name":"stdout","text":"Epoch 2: Train Loss: 1.6243 | Val Acc: 58.52%\n--> Best Model Saved! (58.52%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d170fa9c0674647b3e8a7e6323f29b5"}},"metadata":{}},{"name":"stdout","text":"Epoch 3: Train Loss: 1.3947 | Val Acc: 61.56%\n--> Best Model Saved! (61.56%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bb6351d2c3f4f76bbbe923e7d61d419"}},"metadata":{}},{"name":"stdout","text":"Epoch 4: Train Loss: 1.2244 | Val Acc: 64.78%\n--> Best Model Saved! (64.78%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21438ba9ddfe4204ad5695dfc0c10d9e"}},"metadata":{}},{"name":"stdout","text":"Epoch 5: Train Loss: 1.1212 | Val Acc: 65.14%\n--> Best Model Saved! (65.14%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22365b2b4cdf4c548ae7ada319fe49a8"}},"metadata":{}},{"name":"stdout","text":"Epoch 6: Train Loss: 1.0715 | Val Acc: 67.58%\n--> Best Model Saved! (67.58%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a18218e98904f0ea77380d83b902816"}},"metadata":{}},{"name":"stdout","text":"Epoch 7: Train Loss: 1.0167 | Val Acc: 67.10%\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7662e818394d4b9eb886b547c98bf10a"}},"metadata":{}},{"name":"stdout","text":"Epoch 8: Train Loss: 0.9572 | Val Acc: 69.85%\n--> Best Model Saved! (69.85%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cef95cd9faf64b35b0b315a820c426d5"}},"metadata":{}},{"name":"stdout","text":"Epoch 9: Train Loss: 0.9403 | Val Acc: 69.07%\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16f5f5e31f18433681e894ba0204cb74"}},"metadata":{}},{"name":"stdout","text":"Epoch 10: Train Loss: 0.8966 | Val Acc: 69.79%\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"685818b02f3f494eb14dcb3ab70e474b"}},"metadata":{}},{"name":"stdout","text":"Epoch 11: Train Loss: 0.8728 | Val Acc: 70.14%\n--> Best Model Saved! (70.14%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0982c4648b3c45aaab580dfa321edd0d"}},"metadata":{}},{"name":"stdout","text":"Epoch 12: Train Loss: 0.8543 | Val Acc: 70.26%\n--> Best Model Saved! (70.26%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"370104eccc934ac598f38df68fd139d3"}},"metadata":{}},{"name":"stdout","text":"Epoch 13: Train Loss: 0.8414 | Val Acc: 70.86%\n--> Best Model Saved! (70.86%)\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51a1098f6e0d40778c0d92e7777769f5"}},"metadata":{}},{"name":"stdout","text":"Epoch 14: Train Loss: 0.8340 | Val Acc: 70.02%\n--------------------------------------------------\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15/15 [Train]:   0%|          | 0/1678 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37bbf2d84e2649a29030c42524c17fe3"}},"metadata":{}},{"name":"stdout","text":"Epoch 15: Train Loss: 0.8413 | Val Acc: 71.16%\n--> Best Model Saved! (71.16%)\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"### Final Evalution","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import f1_score, classification_report, accuracy_score\n\n# ==========================================\n# 1. SETUP & DATA PREPARATION\n# ==========================================\ntest_df = pd.read_csv(TEST_CSV_PATH)\n\n# UPDATE: Added missing classes from your warning\nclass_mapper = {\n    'No finding': 0,\n    'Disc space narrowing': 1,\n    'Foraminal stenosis': 2,\n    'Osteophytes': 3,\n    'Spondylolisthesis': 4,      # Correct spelling (likely used in training)\n    'Spondylolysthesis': 4,      # CSV spelling (maps to same class ID 4)\n    'Vertebral collapse': 5,\n    'Scoliosis': 6,\n    'Surgical implant': 7,       # Assigned new ID (Ensure this matches training if used)\n    'Other lesions': 8           # Assigned new ID (Ensure this matches training if used)\n}\n\nprint(\"Mapping labels...\")\ntest_df['label_encoded'] = test_df['lesion_type'].map(class_mapper)\n\n# Drop rows that still have no match (Safety check)\nif test_df['label_encoded'].isnull().any():\n    print(f\"⚠️ Warning: Still dropping {test_df['label_encoded'].isnull().sum()} rows with unknown labels.\")\n    test_df = test_df.dropna(subset=['label_encoded'])\n\ntest_df['label_encoded'] = test_df['label_encoded'].astype(int)\n\n# REMOVED .head(50) -> Running on FULL dataset\ntest_df = test_df.drop_duplicates(subset=['image_id']).reset_index(drop=True)\nprint(f\"Total Test Images: {len(test_df)}\")\n\ntest_dataset = SpineDataset(test_df, TEST_IMG_DIR, transform=val_transforms)\ntest_loader = DataLoader(test_dataset, batch_size=Config['batch_size'], shuffle=False, num_workers=Config['num_workers'])\n\n# ==========================================\n# 2. LOAD MODEL\n# ==========================================\nmodel_path = \"maxvit_best_model.pth\" \nprint(f\"Loading model from: {model_path}\")\n\nmodel.load_state_dict(torch.load(model_path))\nmodel.eval()\n\n# ==========================================\n# 3. FULL INFERENCE LOOP\n# ==========================================\ny_true, y_pred, y_probs = [], [], []\n\nprint(\"Running Full Inference...\")\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader):\n        images = images.to(Config['device'])\n        \n        with torch.amp.autocast('cuda'): \n            outputs = model(images)\n            # Get probabilities\n            probs = torch.softmax(outputs, dim=1)\n            # Get predicted class\n            _, preds = torch.max(outputs, 1)\n        \n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(preds.cpu().numpy())\n        y_probs.extend(probs.cpu().numpy())\n\n# ==========================================\n# 4. METRICS & SAVING\n# ==========================================\ny_true = np.array(y_true)\ny_pred = np.array(y_pred)\n\n# Calculate Accuracy\nacc = accuracy_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred, average='weighted')\n\nprint(\"\\n\" + \"=\"*30)\nprint(f\"Test Accuracy: {acc*100:.2f}%\")\nprint(f\"Weighted F1:   {f1*100:.2f}%\")\nprint(\"=\"*30)\n\n# Print Detailed Report\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred))\n\n# Save Results to CSV\nresults_df = pd.DataFrame({\n    'image_id': test_df['image_id'],\n    'true_label': y_true,\n    'predicted_label': y_pred\n})\nresults_df.to_csv(\"test_predictions.csv\", index=False)\nprint(\"✅ Predictions saved to 'test_predictions.csv'\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-09T19:19:39.920020Z","iopub.execute_input":"2025-12-09T19:19:39.920762Z","iopub.status.idle":"2025-12-09T19:22:13.263959Z","shell.execute_reply.started":"2025-12-09T19:19:39.920732Z","shell.execute_reply":"2025-12-09T19:22:13.263095Z"}},"outputs":[{"name":"stdout","text":"Mapping labels...\nTotal Test Images: 2077\nLoading model from: maxvit_best_model.pth\nRunning Full Inference...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 520/520 [02:32<00:00,  3.41it/s]","output_type":"stream"},{"name":"stdout","text":"\n==============================\nTest Accuracy: 28.12%\nWeighted F1:   28.59%\n==============================\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.22      0.01      0.01      1070\n           1       0.00      0.00      0.00        59\n           2       0.02      0.40      0.03        47\n           3       0.74      0.69      0.72       806\n           4       0.00      0.00      0.00        13\n           5       0.00      0.00      0.00        16\n           6       0.00      0.00      0.00         0\n           7       0.00      0.00      0.00        34\n           8       0.00      0.00      0.00        32\n\n    accuracy                           0.28      2077\n   macro avg       0.11      0.12      0.08      2077\nweighted avg       0.40      0.28      0.29      2077\n\n✅ Predictions saved to 'test_predictions.csv'\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11}]}